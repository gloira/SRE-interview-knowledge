# 操作系统
## 基本定义
操作系统提供了四种抽象模型：
 - 文件：对 I/O 设备的抽象
 - 虚拟内存：对程序存储器的抽象
 - 进程：对一个正在运行程序的抽象
 - 虚拟机：对整个操作系统的抽象
 
我们程序员不会直接和这些硬件打交道，并且每位程序员不可能会掌握所有计算机系统的细节。
所以计算机科学家在硬件的基础之上，安装了一层软件，这层软件能够根据用户输入的指令达到控制硬件的效果，从而满足用户的需求，这样的软件称为 操作系统，它的任务就是为用户程序提供一个更好、更简单、更清晰的计算机模型。也就是说，操作系统相当于是一个中间层，为用户层和硬件提供各自的借口，屏蔽了不同应用和硬件之间的差异，达到统一标准的作用。
![image](https://user-images.githubusercontent.com/81898811/113501580-cfbf1800-9558-11eb-9d8b-e6272f2e9b0e.png)

## 计算机硬件
5个重要组成部分：
- 运算器
- 控制器
--> 运算器和控制及组成了CPU
- 存储器：一种是主存，也就是内存，它是 CPU 主要交互对象，还有一种是外存，比如硬盘软盘等
- 输入设备
- 输出设备
![image](https://user-images.githubusercontent.com/81898811/113501643-5c69d600-9559-11eb-91ff-421845e7629e.png)

CPU(处理器)可能执行简单操作的几个步骤：
- 加载(Load)：从主存中拷贝一个字节或者一个字到内存中，覆盖寄存器先前的内容
- 存储(Store)：将寄存器中的字节或字复制到主存储器中的某个位置，从而覆盖该位置的先前内容
- 操作(Operate)：把两个寄存器的内容复制到 ALU(Arithmetic logic unit)。把两个字进行算术运算，并把结果存储在寄存器中，重写寄存器先前的内容。算术逻辑单元（ALU）是对数字二进制数执行算术和按位运算的组合数字电子电路。
- 跳转(jump)：从指令中抽取一个字，把这个字复制到程序计数器(PC) 中，覆盖原来的值

## 进程
操作系统中最核心的概念就是 进程，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。
### 进程模型
一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。
![image](https://user-images.githubusercontent.com/81898811/113501779-748e2500-955a-11eb-8ba9-3d6d892c0b43.png)
如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。
![image](https://user-images.githubusercontent.com/81898811/113501801-8bcd1280-955a-11eb-8258-f12c62576563.png)
在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。

从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正运行。
![image](https://user-images.githubusercontent.com/81898811/113502193-4827d800-955d-11eb-9742-d24af7e12422.png)
因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），每一个核也只能一次运行一个线程。

由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。

这里的关键思想是认识到一个进程所需的条件，进程是某一类特定活动的总和，它有程序、输入输出以及状态。

### 进程的创建
在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 fork。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。

在 Windows 中，情况正相反，一个简单的 Win32 功能调用 CreateProcess，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的。

### 进程的终止
- 正常退出(自愿的) ： 多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 exit ，在 Windows 中是 ExitProcess。
- 错误退出(自愿的)：比如执行一条不存在的命令，于是编译器就会提醒并退出。
- 严重错误(非自愿的)
- 被其他进程杀死(非自愿的) ： 某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess（注意不是系统调用）。

### 进程的层次结构
在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。
#### UNIX进程体系
在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。
#### Windows进程体系
相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。

### 进程状态
尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。当一个进程开始运行时，它可能会经历下面这几种状态
![image](https://user-images.githubusercontent.com/81898811/113502396-b8832900-955e-11eb-89d2-c282608c3094.png)
- 运行态，运行态指的就是进程实际占用 CPU 时间片运行时
- 就绪态，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态
- 阻塞态，除非某种外部事件发生，否则进程不能运行

### 进程的实现
操作系统为了执行进程间的切换，会维护着一张表，这张表就是 进程表(process table)。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息。
![image](https://user-images.githubusercontent.com/81898811/113502508-4ced8b80-955f-11eb-9a3d-5e0dafa8c333.png)
一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。

## 线程
在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。
### 线程的使用
为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答
- 多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的
- 线程要比进程更轻量级，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。
- 第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度

### 经典的线程模型
进程中拥有一个执行的线程，通常简写为 线程(thread)。线程会有程序计数器，用来记录接着要执行哪一条指令；线程实际是 CPU 上调度执行的实体。
下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行
![image](https://user-images.githubusercontent.com/81898811/113502911-82937400-9561-11eb-83e0-5cf253183c44.png)
下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。
![image](https://user-images.githubusercontent.com/81898811/113502942-9dfe7f00-9561-11eb-9891-2f88e9263bd2.png)
线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，因此一个线程可以读取、写入甚至擦除另一个线程的堆栈。线程之间除了共享同一内存空间外，还具有如下不同的内容
![image](https://user-images.githubusercontent.com/81898811/113503103-51677380-9562-11eb-9d9e-d193eb19893c.png)
上图左边的是同一个进程中每个线程共享的内容，上图右边是每个线程中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。

线程之间的状态转换和进程之间的状态转换是一样的。

每个线程都会有自己的堆栈，如下图所示
![image](https://user-images.githubusercontent.com/81898811/113503127-6ba15180-9562-11eb-8c85-4492bf1485d2.png)

### 线程系统调用
进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 thread_create）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。

当一个线程完成工作后，可以通过调用一个函数（比如 thread_exit）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 thread_join ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。

另一个常见的线程是调用 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。

### 线程实现
主要三种方式：
- 在用户空间中实现线程；
- 在内核空间中实现线程；
- 在用户和内核空间中混合实现线程。

#### 在用户空间中实现线程；
第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构
![image](https://user-images.githubusercontent.com/81898811/113503187-cdfa5200-9562-11eb-8173-89696eb413ad.png)
线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程： pthread_create, pthread_exit, pthread_join 和 pthread_yield。

#### 在内核中实现线程
当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。
![image](https://user-images.githubusercontent.com/81898811/113503212-f5511f00-9562-11eb-8cbe-497b8210d7bd.png)
内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。

所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。

#### 混合实现
结合用户空间和内核空间的优点，设计人员采用了一种内核级线程的方式，然后将用户级线程与某些或者全部内核线程多路复用起来
![image](https://user-images.githubusercontent.com/81898811/113503249-377a6080-9563-11eb-9c23-a38243b79d24.png)
在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。

## 进程间通信
进程是需要频繁的和其他进程进行交流的。下面我们会一起讨论有关 进程间通信(Inter Process Communication, IPC) 的问题。大致来说，进程间的通信机制可以分为 6 种
![image](https://user-images.githubusercontent.com/81898811/113503275-609af100-9563-11eb-8c56-c3388c0751d2.png)

### 信号 signal
信号是 UNIX 系统最先开始使用的进程间通信机制，因为 Linux 是继承于 UNIX 的，所以 Linux 也支持信号机制，通过向一个或多个进程发送异步事件信号来实现，信号可以从键盘或者访问不存在的位置等地方产生；信号通过 shell 将任务发送给子进程。

你可以在 Linux 系统上输入 kill -l 来列出系统使用的信号，下面是我提供的一些信号
![image](https://user-images.githubusercontent.com/81898811/113503353-e9b22800-9563-11eb-906a-0643bfa836f8.png)
进程可以选择忽略发送过来的信号，但是有两个是不能忽略的：SIGSTOP 和 SIGKILL 信号。SIGSTOP 信号会通知当前正在运行的进程执行关闭操作，SIGKILL 信号会通知当前进程应该被杀死。除此之外，进程可以选择它想要处理的信号，进程也可以选择阻止信号，如果不阻止，可以选择自行处理，也可以选择进行内核处理。如果选择交给内核进行处理，那么就执行默认处理。

操作系统会中断目标程序的进程来向其发送信号、在任何非原子指令中，执行都可以中断，如果进程已经注册了新号处理程序，那么就执行进程，如果没有注册，将采用默认处理的方式。

### 管道 pipe
Linux 系统中的进程可以通过建立管道 pipe 进行通信

在两个进程之间，可以建立一个通道，一个进程向这个通道里写入字节流，另一个进程从这个管道中读取字节流。管道是同步的，当进程尝试从空管道读取数据时，该进程会被阻塞，直到有可用数据为止。shell 中的管线 pipelines 就是用管道实现的，当 shell 发现输出

``` sort <f | head ```

它会创建两个进程，一个是 sort，一个是 head，sort，会在这两个应用程序之间建立一个管道使得 sort 进程的标准输出作为 head 程序的标准输入。sort 进程产生的输出就不用写到文件中了，如果管道满了系统会停止 sort 以等待 head 读出数据
管道实际上就是``` | ```，两个应用程序不知道有管道的存在，一切都是由 shell 管理和控制的。

### 共享内存 shared memory
两个进程之间还可以通过共享内存进行进程间通信，其中两个或者多个进程可以访问公共内存空间。两个进程的共享工作是通过共享内存完成的，一个进程所作的修改可以对另一个进程可见(很像线程间的通信)。

在使用共享内存前，需要经过一系列的调用流程，流程如下

- 创建共享内存段或者使用已创建的共享内存段 ```shmget()```
- 将进程附加到已经创建的内存段中 ```shmat()```
- 从已连接的共享内存段分离进程 ```shmdt()```
- 对共享内存段执行控制操作 ```shmctl()```

### 先入先出队列 FIFO
先入先出队列 FIFO 通常被称为 命名管道(Named Pipes)，命名管道的工作方式与常规管道非常相似，但是确实有一些明显的区别。未命名的管道没有备份文件：操作系统负责维护内存中的缓冲区，用来将字节从写入器传输到读取器。一旦写入或者输出终止的话，缓冲区将被回收，传输的数据会丢失。相比之下，命名管道具有支持文件和独特 API ，命名管道在文件系统中作为设备的专用文件存在。当所有的进程通信完成后，命名管道将保留在文件系统中以备后用。命名管道具有严格的 FIFO 行为

写入的第一个字节是读取的第一个字节，写入的第二个字节是读取的第二个字节，依此类推。

### 消息队列 Message Queue
一听到消息队列这个名词你可能不知道是什么意思，消息队列是用来描述内核寻址空间内的内部链接列表。可以按几种不同的方式将消息按顺序发送到队列并从队列中检索消息。每个消息队列由 IPC 标识符唯一标识。消息队列有两种模式，一种是严格模式， 严格模式就像是 FIFO 先入先出队列似的，消息顺序发送，顺序读取。还有一种模式是 非严格模式，消息的顺序性不是非常重要。

### 套接字 Socket
还有一种管理两个进程间通信的是使用``` socket```，socket 提供端到端的双相通信。一个套接字可以与一个或多个进程关联。就像管道有命令管道和未命名管道一样，套接字也有两种模式，套接字一般用于两个进程之间的网络通信，网络套接字需要来自诸如```TCP（传输控制协议）```或较低级别```UDP（用户数据报协议）```等基础协议的支持。

套接字有以下几种分类

- 顺序包套接字(Sequential Packet Socket)： 此类套接字为最大长度固定的数据报提供可靠的连接。此连接是双向的并且是顺序的。
- 数据报套接字(Datagram Socket)：数据包套接字支持双向数据流。数据包套接字接受消息的顺序与发送者可能不同。
- 流式套接字(Stream Socket)：流套接字的工作方式类似于电话对话，提供双向可靠的数据流。
- 原始套接字(Raw Socket)： 可以使用原始套接字访问基础通信协议

## 调度
当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程/线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程/线程可以运行。操作系统中有一个叫做 ```调度程序(scheduler)``` 的角色存在，它就是做这件事儿的，该程序使用的算法叫做``` 调度算法(scheduling algorithm)```。

### 调度算法的分类
毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境
- 批处理(Batch) : 商业领域
- 交互式(Interactive)： 交互式用户环境
- 实时(Real time)

### 批处理中的调度
#### 先来先服务
最简单的非抢占式调度算法的设计就是```先来先服务(first-come,first-serverd)```。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。

这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。

#### 最短作业优先
批处理中，第二种调度算法是```最短作业优先(Shortest Job First)```，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法

需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。

#### 最短剩余时间优先
最短作业优先的抢占式版本被称作为 ```最短剩余时间优先(Shortest Remaining Time Next) ```算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。

### 交互式系统中的调度
#### 轮询制度
一种最古老、最简单、最公平并且最广泛使用的算法就是 轮询算法(round-robin)。每个进程都会被分配一个时间段，称为时间片(quantum)，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。
![image](https://user-images.githubusercontent.com/81898811/113503976-d1440c80-9567-11eb-9ae1-fe094eb863af.png)

#### 优先级调度
轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了```优先级调度(priority scheduling)```
它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。

#### 多级队列
最早使用优先级调度的系统是 CTSS(Compatible TimeSharing System)。CTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。

#### 最短进程优先
最短进程优先是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。

#### 保证调度
一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。

#### 彩票调度
对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 彩票调度(lottery scheduling)算法。

其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。

#### 公平分享调度
到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。

为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。

### 实时系统中的调度
实时系统(real-time) 是一个时间扮演了重要作用的系统。实时系统可以分为两类，硬实时(hard real time) 和 软实时(soft real time) 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。

## 内存管理
![image](https://user-images.githubusercontent.com/81898811/113504248-6e537500-9569-11eb-9d7c-bfd7e0a3558a.png)

## 地址空间（空间管理）
如果要使多个应用程序同时运行在内存中，必须要解决两个问题：```保护```和 ```重定位```。第一种解决方式是用```保护密钥标记内存块```，并将执行过程的密钥与提取的每个存储字的密钥进行比较。这种方式只能解决第一种问题（破坏操作系统），但是不能解决多进程在内存中同时运行的问题。

还有一种更好的方式是创造一个存储器抽象：```地址空间(the address space)```。就像进程的概念创建了一种抽象的 CPU 来运行程序，地址空间也创建了一种抽象内存供程序使用。

#### 基址寄存器和变址寄存器
最简单的办法是使用动态重定位(dynamic relocation)技术，它就是通过一种简单的方式将每个进程的地址空间映射到物理内存的不同区域。还有一种方式是使用基址寄存器和变址寄存器。
- 基址寄存器：存储数据内存的起始位置
- 变址寄存器：存储应用程序的长度。
每当进程引用内存以获取指令或读取、写入数据时，CPU 都会自动将```基址值```添加到进程生成的地址中，然后再将其发送到内存总线上。同时，它检查程序提供的地址是否大于或等于变址寄存器 中的值。如果程序提供的地址要超过```变址寄存器```的范围，那么会产生错误并中止访问。

### 交换技术
在程序运行过程中，经常会出现内存不足的问题。

针对上面内存不足的问题，提出了两种处理方式：最简单的一种方式就是```交换(swapping)```技术，即把一个进程完整的调入内存，然后再内存中运行一段时间，再把它放回磁盘。空闲进程会存储在磁盘中，所以这些进程在没有运行时不会占用太多内存。另外一种策略叫做```虚拟内存(virtual memory)```，虚拟内存技术能够允许应用程序部分的运行在内存中。下面我们首先先探讨一下交换

#### 交换过程
![image](https://user-images.githubusercontent.com/81898811/113504424-97283a00-956a-11eb-970b-4087890a1542.png)
刚开始的时候，只有进程 A 在内存中，然后从创建进程 B 和进程 C 或者从磁盘中把它们换入内存，然后在图 d 中，A 被换出内存到磁盘中，最后 A 重新进来。因为图 g 中的进程 A 现在到了不同的位置，所以在装载过程中需要被重新定位，或者在交换程序时通过软件来执行；或者在程序执行期间通过硬件来重定位。基址寄存器和变址寄存器就适用于这种情况。
![image](https://user-images.githubusercontent.com/81898811/113504437-a7d8b000-956a-11eb-9e28-4def0f4003f4.png)

交换在内存创建了多个 空闲区(hole)，内存会把所有的空闲区尽可能向下移动合并成为一个大的空闲区。这项技术称为内存紧缩(memory compaction)。但是这项技术通常不会使用，因为这项技术会消耗很多 CPU 时间。

### 空闲内存管理
在进行内存动态分配时，操作系统必须对其进行管理。大致上说，有两种监控内存使用的方式

- 位图(bitmap)
- 空闲列表(free lists)

#### 使用位图的存储管理
使用位图方法时，内存可能被划分为小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用（或者相反）。一块内存区域和其对应的位图如下
![image](https://user-images.githubusercontent.com/81898811/113504508-187fcc80-956b-11eb-9f92-c8b0bd240ecf.png)
位图提供了一种简单的方法在固定大小的内存中跟踪内存的使用情况，因为位图的大小取决于内存和分配单元的大小。这种方法有一个问题是，当决定为把具有 k 个分配单元的进程放入内存时，内容管理器(memory manager) 必须搜索位图，在位图中找出能够运行 k 个连续 0 位的串。在位图中找出制定长度的连续 0 串是一个很耗时的操作，这是位图的缺点。（可以简单理解为在杂乱无章的数组中，找出具有一大长串空闲的数组单元）

#### 使用链表进行管理
另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表，段会包含进程或者是两个进程的空闲区域。可用上面的图 c 来表示内存的使用情况。链表中的每一项都可以代表一个 空闲区(H) 或者是进程(P)的起始标志，长度和下一个链表项的位置。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以为创建的进程（或者从磁盘中换入的进程）分配内存。我们先假设内存管理器知道应该分配多少内存，最简单的算法是使用 首次适配(first fit)。内存管理器会沿着段列表进行扫描，直到找个一个足够大的空闲区为止。 除非空闲区大小和要分配的空间大小一样，否则将空闲区分为两部分，一部分供进程使用；一部分生成新的空闲区。首次适配算法是一种速度很快的算法，因为它会尽可能的搜索链表。

首次适配的一个小的变体是 下次适配(next fit)。它和首次匹配的工作方式相同，只有一个不同之处那就是下次适配在每次找到合适的空闲区时就会记录当时的位置，以便下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次匹配算法那样每次都会从头开始搜索。

另外一个著名的并且广泛使用的算法是 最佳适配(best fit)。最佳适配会从头到尾寻找整个链表，找出能够容纳进程的最小空闲区。

## 虚拟内存
尽管基址寄存器和变址寄存器用来创建地址空间的抽象，但是这有一个其他的问题需要解决：管理软件的不断增大(managing bloatware)。虚拟内存的基本思想是，每个程序都有自己的地址空间，这个地址空间被划分为多个称为```页面(page)```的块。每一页都是连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，硬件会立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

### 分页
大部分使用虚拟内存的系统中都会使用一种 分页(paging) 技术。在任何一台计算机上，程序会引用使用一组内存地址。当程序执行

``` MOV REG,1000 ```

这条指令时，它会把内存地址为 1000 的内存单元的内容复制到 REG 中（或者相反，这取决于计算机）。地址可以通过索引、基址寄存器、段寄存器或其他方式产生。

这些程序生成的地址被称为 虚拟地址(virtual addresses) 并形成虚拟地址空间(virtual address space)，在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存中线上，读写操作都使用同样地址的物理内存。在使用虚拟内存时，虚拟地址不会直接发送到内存总线上。相反，会使用 MMU(Memory Management Unit) 内存管理单元把虚拟地址映射为物理内存地址，像下图这样
![image](https://user-images.githubusercontent.com/81898811/113504952-54686100-956e-11eb-8a7a-c3d910afd117.png)
下面这幅图展示了这种映射是如何工作的
![image](https://user-images.githubusercontent.com/81898811/113504981-7eba1e80-956e-11eb-9518-774499893e30.png)
页表给出虚拟地址与物理内存地址之间的映射关系。每一页起始于 4096 的倍数位置，结束于 4095 的位置，所以 4K 到 8K 实际为 4096 - 8191 ，8K - 12K 就是 8192 - 12287

在这个例子中，我们可能有一个 16 位地址的计算机，地址从 0 - 64 K - 1，这些是虚拟地址。然而只有 32 KB 的物理地址。所以虽然可以编写 64 KB 的程序，但是程序无法全部调入内存运行，在磁盘上必须有一个最多 64 KB 的程序核心映像的完整副本，以保证程序片段在需要时被调入内存。

### 页表
虚拟页号可作为页表的索引用来找到虚拟页中的内容。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成物理地址。
因此，页表的目的是把虚拟页映射到页框中。从数学上说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。
#### 页表项的结构
下面我们探讨一下页表项的具体结构，上面你知道了页表项的大致构成，是由页框号和在/不在位构成的，现在我们来具体探讨一下页表项的构成
![image](https://user-images.githubusercontent.com/81898811/113505043-0011b100-956f-11eb-804d-b59d7cd84fca.png)
页表项的结构是与机器相关的，但是不同机器上的页表项大致相同。上面是一个页表项的构成，不同计算机的页表项可能不同，但是一般来说都是 32 位的。页表项中最重要的字段就是页框号(Page frame number)。毕竟，页表到页框最重要的一步操作就是要把此值映射过去。下一个比较重要的就是在/不在位，如果此位上的值是 1，那么页表项是有效的并且能够被使用。如果此值是 0 的话，则表示该页表项对应的虚拟页面不在内存中，访问该页面会引起一个缺页异常(page fault)。

保护位(Protection) 告诉我们哪一种访问是允许的，啥意思呢？最简单的表示形式是这个域只有一位，0 表示可读可写，1 表示的是只读。

修改位(Modified) 和 访问位(Referenced) 会跟踪页面的使用情况。当一个页面被写入时，硬件会自动的设置修改位。修改位在页面重新分配页框时很有用。如果一个页面已经被修改过（即它是 脏 的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是 干净的），那么重新分配时这个页框会被直接丢弃，因为磁盘上的副本仍然是有效的。这个位有时也叫做 脏位(dirty bit)，因为它反映了页面的状态。

访问位(Referenced) 在页面被访问时被设置，不管是读还是写。这个值能够帮助操作系统在发生缺页中断时选择要淘汰的页。不再使用的页要比正在使用的页更适合被淘汰。这个位在后面要讨论的页面置换算法中作用很大。

最后一位用于禁止该页面被高速缓存，这个功能对于映射到设备寄存器还是内存中起到了关键作用。通过这一位可以禁用高速缓存。具有独立的 I/O 空间而不是用内存映射 I/O 的机器来说，并不需要这一位。

## 页面置换算法

### 最优页面置换算法
最优的页面置换算法的工作流程如下：在缺页中断发生时，这些页面之一将在下一条指令（包含该指令的页面）上被引用。其他页面则可能要到 10、100 或者 1000 条指令后才会被访问。每个页面都可以用在该页首次被访问前所要执行的指令数作为标记。

最优化的页面算法表明应该标记最大的页面。如果一个页面在 800 万条指令内不会被使用，另外一个页面在 600 万条指令内不会被使用，则置换前一个页面，从而把需要调入这个页面而发生的缺页中断推迟。计算机也像人类一样，会把不愿意做的事情尽可能的往后拖。

这个算法最大的问题时无法实现。当缺页中断发生时，操作系统无法知道各个页面的下一次将在什么时候被访问。这种算法在实际过程中根本不会使用。

### 最近未使用页面置换算法 NRU
为了能够让操作系统收集页面使用信息，大部分使用虚拟地址的计算机都有两个状态位，R 和 M，来和每个页面进行关联。每当引用页面（读入或写入）时都设置 R，写入（即修改）页面时设置 M，这些位包含在每个页表项中，就像下面所示
![image](https://user-images.githubusercontent.com/81898811/113505043-0011b100-956f-11eb-804d-b59d7cd84fca.png)
因为每次访问时都会更新这些位，因此由硬件来设置它们非常重要。一旦某个位被设置为 1，就会一直保持 1 直到操作系统下次来修改此位。

如果硬件没有这些位，那么可以使用操作系统的缺页中断和时钟中断机制来进行模拟。当启动一个进程时，将其所有的页面都标记为不在内存；一旦访问任何一个页面就会引发一次缺页中断，此时操作系统就可以设置 R 位(在它的内部表中)，修改页表项使其指向正确的页面，并设置为 READ ONLY 模式，然后重新启动引起缺页中断的指令。如果页面随后被修改，就会发生另一个缺页异常。从而允许操作系统设置 M 位并把页面的模式设置为 READ/WRITE。

可以用 R 位和 M 位来构造一个简单的页面置换算法：当启动一个进程时，操作系统将其所有页面的两个位都设置为 0。R 位定期的被清零（在每个时钟中断）。用来将最近未引用的页面和已引用的页面分开。

当出现缺页中断后，操作系统会检查所有的页面，并根据它们的 R 位和 M 位将当前值分为四类：

第 0 类：没有引用 R，没有修改 M
第 1 类：没有引用 R，已修改 M
第 2 类：引用 R ，没有修改 M
第 3 类：已被访问 R，已被修改 M
尽管看起来好像无法实现第一类页面，但是当第三类页面的 R 位被时钟中断清除时，它们就会发生。时钟中断不会清除 M 位，因为需要这个信息才能知道是否写回磁盘中。清除 R 但不清除 M 会导致出现一类页面。

NRU(Not Recently Used) 算法从编号最小的非空类中随机删除一个页面。此算法隐含的思想是，在一个时钟内（约 20 ms）淘汰一个已修改但是没有被访问的页面要比一个大量引用的未修改页面好，NRU 的主要优点是易于理解并且能够有效的实现。

### 先进先出页面置换算法 FIFO
另一种开销较小的方式是使用 FIFO(First-In,First-Out) 算法，这种类型的数据结构也适用在页面置换算法中。由操作系统维护一个所有在当前内存中的页面的链表，最早进入的放在表头，最新进入的页面放在表尾。在发生缺页异常时，会把头部的页移除并且把新的页添加到表尾。

### 第二次机会页面置换算法
我们上面学到的 FIFO 链表页面有个缺陷，那就是出链和入链并不会进行 check 检查，这样就会容易把经常使用的页面置换出去，为了避免这一问题，我们对该算法做一个简单的修改：我们检查最老页面的 R 位，如果是 0 ，那么这个页面就是最老的而且没有被使用，那么这个页面就会被立刻换出。如果 R 位是 1，那么就清除此位，此页面会被放在链表的尾部，修改它的装入时间就像刚放进来的一样。然后继续搜索。

这种算法叫做 第二次机会(second chance)算法，就像下面这样，我们看到页面 A 到 H 保留在链表中，并按到达内存的时间排序。

假设缺页异常发生在时刻 20 处，这时最老的页面是 A ，它是在 0 时刻到达的。如果 A 的 R 位是 0，那么它将被淘汰出内存，或者把它写回磁盘（如果它已经被修改过），或者只是简单的放弃（如果它是未被修改过）。另一方面，如果它的 R 位已经设置了，则将 A 放到链表的尾部并且重新设置装入时间为当前时刻（20 处），然后清除 R 位。然后从 B 页面开始继续搜索合适的页面。

寻找第二次机会的是在最近的时钟间隔中未被访问过的页面。如果所有的页面都被访问过，该算法就会被简化为单纯的 FIFO 算法。具体来说，假设图 a 中所有页面都设置了 R 位。操作系统将页面依次移到链表末尾，每次都在添加到末尾时清除 R 位。最后，算法又会回到页面 A，此时的 R 位已经被清除，那么页面 A 就会被执行出链处理，因此算法能够正常结束。

### 时钟页面置换算法
一种比较好的方式是把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面。如下图所示
![image](https://user-images.githubusercontent.com/81898811/113505331-9692a200-9570-11eb-85cd-b86ae254ddb5.png)
当缺页错误出现时，算法首先检查表针指向的页面，如果它的 R 位是 0 就淘汰该页面，并把新的页面插入到这个位置，然后把表针向前移动一位；如果 R 位是 1 就清除 R 位并把表针前移一个位置。重复这个过程直到找到了一个 R 位为 0 的页面位置。了解这个算法的工作方式，就明白为什么它被称为 时钟(clokc)算法了。

### 最近最少使用页面置换算法 LRU Least Recently Used
在前面几条指令中频繁使用的页面和可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面有可能在未来一段时间内仍不会被使用。这个思想揭示了一个可以实现的算法：在缺页中断时，置换未使用时间最长的页面。这个策略称为 LRU(Least Recently Used) ，最近最少使用页面置换算法。

虽然 LRU 在理论上是可以实现的，但是从长远看来代价比较高。为了完全实现 LRU，会在内存中维护一个所有页面的链表，最频繁使用的页位于表头，最近最少使用的页位于表尾。困难的是在每次内存引用时更新整个链表。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常耗时的操作，即使使用硬件来实现也是一样的费时。

### 用软件模拟 LRU
尽管上面的 LRU 算法在原则上是可以实现的，但是很少有机器能够拥有那些特殊的硬件。上面是硬件的实现方式，那么现在考虑要用软件来实现 LRU 。一种可以实现的方案是 NFU(Not Frequently Used，最不常用)算法。它需要一个软件计数器来和每个页面关联，初始化的时候是 0 。在每个时钟中断时，操作系统会浏览内存中的所有页，会将每个页面的 R 位（0 或 1）加到它的计数器上。这个计数器大体上跟踪了各个页面访问的频繁程度。当缺页异常出现时，则置换计数器值最小的页面。

只需要对 NFU 做一个简单的修改就可以让它模拟 LRU，这个修改有两个步骤

- 首先，在 R 位被添加进来之前先把计数器右移一位；
- 第二步，R 位被添加到最左边的位而不是最右边的位。

修改以后的算法称为 ```老化(aging) ```算法，下图解释了老化算法是如何工作的。
![image](https://user-images.githubusercontent.com/81898811/113505438-6a2b5580-9571-11eb-9302-621b32a1bb3c.png)
我们假设在第一个时钟周期内页面 0 - 5 的 R 位依次是 1，0，1，0，1，1，（也就是页面 0 是 1，页面 1 是 0，页面 2 是 1 这样类推）。也就是说，在 0 个时钟周期到 1 个时钟周期之间，0，2，4，5 都被引用了，从而把它们的 R 位设置为 1，剩下的设置为 0 。在相关的六个计数器被右移之后 R 位被添加到 左侧 ，就像上图中的 a。剩下的四列显示了接下来的四个时钟周期内的六个计数器变化。

CPU正在以某个频率前进，该频率的周期称为时钟滴答或时钟周期。一个 100Mhz 的处理器每秒将接收100,000,000个时钟滴答。

当缺页异常出现时，将置换（就是移除）计数器值最小的页面。如果一个页面在前面 4 个时钟周期内都没有被访问过，那么它的计数器应该会有四个连续的 0 ，因此它的值肯定要比前面 3 个时钟周期内都没有被访问过的页面的计数器小。

这个算法与 LRU 算法有两个重要的区别：看一下上图中的 e，第三行和第五行

### 工作集时钟页面置换算法 WSCLOCK
当缺页异常发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法还是比较浪费时间的。一个对基本工作集算法的提升是基于时钟算法但是却使用工作集的信息，这种算法称为WSClock(工作集时钟)。由于它的实现简单并且具有高性能，因此在实践中被广泛应用。

与时钟算法一样，所需的数据结构是一个以页框为元素的循环列表，就像下面这样
![image](https://user-images.githubusercontent.com/81898811/113505473-abbc0080-9571-11eb-9e82-80f5839072ea.png)

 工作集时钟页面置换算法的操作：a) 和 b) 给出 R = 1 时所发生的情形；c) 和 d) 给出 R = 0 的例子

最初的时候，该表是空的。当装入第一个页面后，把它加载到该表中。随着更多的页面的加入，它们形成一个环形结构。每个表项包含来自基本工作集算法的上次使用时间，以及 R 位（已标明）和 M 位（未标明）。

与时钟算法一样，在每个缺页异常时，首先检查指针指向的页面。如果 R 位被是设置为 1，该页面在当前时钟周期内就被使用过，那么该页面就不适合被淘汰。然后把该页面的 R 位置为 0，指针指向下一个页面，并重复该算法。该事件序列化后的状态参见图 b。

现在考虑指针指向的页面 R = 0 时会发生什么，参见图 c，如果页面的使用期限大于 t 并且页面为被访问过，那么这个页面就不会在工作集中，并且在磁盘上会有一个此页面的副本。申请重新调入一个新的页面，并把新的页面放在其中，如图 d 所示。另一方面，如果页面被修改过，就不能重新申请页面，因为这个页面在磁盘上没有有效的副本。为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作。毕竟，有可能存在一个老的，没有被修改过的页面可以立即使用。

原则上来说，所有的页面都有可能因为磁盘I/O 在某个时钟周期内被调度。为了降低磁盘阻塞，需要设置一个限制，即最大只允许写回 n 个页面。一旦达到该限制，就不允许调度新的写操作。

那么就有个问题，指针会绕一圈回到原点的，如果回到原点，它的起始点会发生什么？这里有两种情况：

- 至少调度了一次写操作
- 没有调度过写操作

在第一种情况中，指针仅仅是不停的移动，寻找一个未被修改过的页面。由于已经调度了一个或者多个写操作，最终会有某个写操作完成，它的页面会被标记为未修改。置换遇到的第一个未被修改过的页面，这个页面不一定是第一个被调度写操作的页面，因为硬盘驱动程序为了优化性能可能会把写操作重排序。

对于第二种情况，所有的页面都在工作集中，否则将至少调度了一个写操作。由于缺乏额外的信息，最简单的方法就是置换一个未被修改的页面来使用，扫描中需要记录未被修改的页面的位置，如果不存在未被修改的页面，就选定当前页面并把它写回磁盘。

### 页面置换算法小结
算法	                             注释
最优算法	                         不可实现，但可以用作基准
NRU(最近未使用) 算法	              和 LRU 算法很相似
FIFO(先进先出) 算法	               有可能会抛弃重要的页面
第二次机会算法	                     比 FIFO 有较大的改善
时钟算法	                         实际使用
LRU(最近最少)算法	                比较优秀，但是很难实现
NFU(最不经常使用)算法	            和 LRU 很类似
老化算法	                        近似 LRU 的高效算法
工作集算法	                       实施起来开销很大
工作集时钟算法	                    比较有效的算法

- 最优算法在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，因此实际上该算法不能使用。然而，它可以作为衡量其他算法的标准。

- NRU 算法根据 R 位和 M 位的状态将页面氛围四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。

- FIFO 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。

- 第二次机会算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。

- 时钟 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。

- LRU 算法是一个非常优秀的算法，但是没有特殊的硬件(TLB)很难实现。如果没有硬件，就不能使用 LRU 算法。

- NFU 算法是一种近似于 LRU 的算法，它的性能不是非常好。

- 老化 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择

最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。WSClock 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。

总之，最好的算法是老化算法和WSClock算法。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。

## 文件
### 文件命名
文件是一种抽象机制，它提供了一种方式用来存储信息以及在后面进行读取。可能任何一种机制最重要的特性就是管理对象的命名方式。在创建一个文件后，它会给文件一个命名。当进程终止时，文件会继续存在，并且其他进程可以使用名称访问该文件。

文件命名规则对于不同的操作系统来说是不一样的，但是所有现代操作系统都允许使用 1 - 8 个字母的字符串作为合法文件名。

某些文件区分大小写字母，而大多数则不区分。UNIX 属于第一类；历史悠久的 MS-DOS 属于第二类（顺便说一句，尽管 MS-DOS 历史悠久，但 MS-DOS 仍在嵌入式系统中非常广泛地使用，因此它绝不是过时的）；因此，UNIX 系统会有三种不同的命名文件：maria、Maria、MARIA 。在 MS-DOS ，所有这些命名都属于相同的文件。

许多操作系统支持两部分的文件名，它们之间用 . 分隔开，比如文件名 prog.c。原点后面的文件称为 文件扩展名(file extension) ，文件扩展名通常表示文件的一些信息。

### 文件结构
三种不同的文件。 a) 字节序列 。b) 记录序列。c) 树

上图中的 a 是一种无结构的字节序列，操作系统不关心序列的内容是什么，操作系统能看到的就是字节(bytes)。其文件内容的任何含义只在用户程序中进行解释。UNIX 和 Windows 都采用这种办法。

图 b 表示在文件结构上的第一部改进。在这个模型中，文件是具有固定长度记录的序列，每个记录都有其内部结构。 把文件作为记录序列的核心思想是：读操作返回一个记录，而写操作重写或者追加一个记录。第三种文件结构如上图 c 所示。在这种组织结构中，文件由一颗记录树构成，记录树的长度不一定相同，每个记录树都在记录中的固定位置包含一个key 字段。这棵树按 key 进行排序，从而可以对特定的 key 进行快速查找。

### 文件类型
很多操作系统支持多种文件类型。例如，UNIX（同样包括 OS X）和 Windows 都具有常规的文件和目录。除此之外，UNIX 还具有字符特殊文件(character special file) 和 块特殊文件(block special file)。常规文件(Regular files) 是包含有用户信息的文件。用户一般使用的文件大都是常规文件，常规文件一般包括 可执行文件、文本文件、图像文件，从常规文件读取数据或将数据写入时，内核会根据文件系统的规则执行操作，是写入可能被延迟，记录日志或者接受其他操作。

### 文件访问
早期的操作系统只有一种访问方式：序列访问(sequential access)。在这些系统中，进程可以按照顺序读取所有的字节或文件中的记录，但是不能跳过并乱序执行它们。顺序访问文件是可以返回到起点的，需要时可以多次读取该文件。当存储介质是磁带而不是磁盘时，顺序访问文件很方便。

在使用磁盘来存储文件时，可以不按照顺序读取文件中的字节或者记录，或者按照关键字而不是位置来访问记录。这种能够以任意次序进行读取的称为随机访问文件(random access file)。许多应用程序都需要这种方式。

随机访问文件对许多应用程序来说都必不可少，例如，数据库系统。如果乘客打电话预定某航班机票，订票程序必须能够直接访问航班记录，而不必先读取其他航班的成千上万条记录。

有两种方法可以指示从何处开始读取文件。第一种方法是直接使用 read 从头开始读取。另一种是用一个特殊的 seek 操作设置当前位置，在 seek 操作后，从这个当前位置顺序地开始读文件。UNIX 和 Windows 使用的是后面一种方式。

### 文件属性
文件包括文件名和数据。除此之外，所有的操作系统还会保存其他与文件相关的信息，如文件创建的日期和时间、文件大小。我们可以称这些为文件的属性(attributes)。有些人也喜欢把它们称作 元数据(metadata)。文件的属性在不同的系统中差别很大。文件的属性只有两种状态：设置(set) 和 清除(clear)。

### 文件操作
使用文件的目的是用来存储信息并方便以后的检索。对于存储和检索，不同的系统提供了不同的操作。以下是与文件有关的最常用的一些系统调用：

- Create，创建不包含任何数据的文件。调用的目的是表示文件即将建立，并对文件设置一些属性。
- Delete，当文件不再需要，必须删除它以释放内存空间。为此总会有一个系统调用来删除文件。
- Open，在使用文件之前，必须先打开文件。这个调用的目的是允许系统将属性和磁盘地址列表保存到主存中，用来以后的快速访问。
- Close，当所有进程完成时，属性和磁盘地址不再需要，因此应关闭文件以释放表空间。很多系统限制进程打开文件的个数，以此达到鼓励用户关闭不再使用的文件。磁盘以块为单位写入，关闭文件时会强制写入最后一块，即使这个块空间内部还不满。
- Read，数据从文件中读取。通常情况下，读取的数据来自文件的当前位置。调用者必须指定需要读取多少数据，并且提供存放这些数据的缓冲区。
- Write，向文件写数据，写操作一般也是从文件的当前位置开始进行。如果当前位置是文件的末尾，则会直接追加进行写入。如果当前位置在文件中，则现有数据被覆盖，并且永远消失。
- append，使用 append 只能向文件末尾添加数据。
- seek，对于随机访问的文件，要指定从何处开始获取数据。通常的方法是用 seek 系统调用把当前位置指针指向文件中的特定位置。seek 调用结束后，就可以从指定位置开始读写数据了。
- get attributes，进程运行时通常需要读取文件属性。
- set attributes，用户可以自己设置一些文件属性，甚至是在文件创建之后，实现该功能的是 set attributes 系统调用。
- rename，用户可以自己更改已有文件的名字，rename 系统调用用于这一目的。

## 目录
文件系统通常提供目录(directories) 或者 文件夹(folders) 用于记录文件的位置，在很多系统中目录本身也是文件。

### 一级目录系统
目录系统最简单的形式是有一个能够包含所有文件的目录。这种目录被称为根目录(root directory)，由于根目录的唯一性，所以其名称并不重要。在最早期的个人计算机中，这种系统很常见，部分原因是因为只有一个用户。下面是一个单层目录系统的例子
![image](https://user-images.githubusercontent.com/81898811/113544249-80412080-961a-11eb-841e-1f4c0a8cf39e.png)
含有四个文件的单层目录系统

该目录中有四个文件。这种设计的优点在于简单，并且能够快速定位文件，毕竟只有一个地方可以检索。这种目录组织形式现在一般用于简单的嵌入式设备（如数码相机和某些便携式音乐播放器）上使用。

### 层次目录系统
对于简单的应用而言，一般都用单层目录方式，但是这种组织形式并不适合于现代计算机，因为现代计算机含有成千上万个文件和文件夹。如果都放在根目录下，查找起来会非常困难。为了解决这一问题，出现了层次目录系统(Hierarchical Directory Systems)，也称为目录树。通过这种方式，可以用很多目录把文件进行分组。进而，如果多个用户共享同一个文件服务器，比如公司的网络系统，每个用户可以为自己的目录树拥有自己的私人根目录。这种方式的组织结构如下
![image](https://user-images.githubusercontent.com/81898811/113544372-b67ea000-961a-11eb-9063-93c624fe3675.png)
根目录含有目录 A、B 和 C ，分别属于不同的用户，其中两个用户个字创建了子目录。用户可以创建任意数量的子目录，现代文件系统都是按照这种方式组织的。

### 路径名
当目录树组织文件系统时，需要有某种方法指明文件名。常用的方法有两种，第一种方式是每个文件都会用一个绝对路径名(absolute path name)，它由根目录到文件的路径组成。

另外一种指定文件名的方法是 相对路径名(relative path name)。它常常和 工作目录(working directory) （也称作 当前目录(current directory)）一起使用。用户可以指定一个目录作为当前工作目录。例如，如果当前目录是 /usr/ast，那么绝对路径 /usr/ast/mailbox可以直接使用 mailbox 来引用。

### 目录操作
不同文件中管理目录的系统调用的差别比管理文件的系统调用差别大。为了了解这些系统调用有哪些以及它们怎样工作，下面给出一个例子（取自 UNIX）。

- Create，创建目录，除了目录项 . 和 .. 外，目录内容为空。
- Delete，删除目录，只有空目录可以删除。只包含 . 和 .. 的目录被认为是空目录，这两个目录项通常不能删除
- opendir，目录内容可被读取。例如，未列出目录中的全部文件，程序必须先打开该目录，然后读其中全部文件的文件名。与打开和读文件相同，在读目录前，必须先打开文件。
- closedir，读目录结束后，应该关闭目录用于释放内部表空间。
- readdir，系统调用 readdir 返回打开目录的下一个目录项。以前也采用 read 系统调用来读取目录，但是这种方法有一个缺点：程序员必须了解和处理目录的内部结构。相反，不论采用哪一种目录结构，readdir 总是以标准格式返回一个目录项。
- rename，在很多方面目录和文件都相似。文件可以更换名称，目录也可以。
-link，链接技术允许在多个目录中出现同一个文件。这个系统调用指定一个存在的文件和一个路径名，并建立从该文件到路径所指名字的链接。这样，可以在多个目录中出现同一个文件。有时也被称为硬链接(hard link)。
- unlink，删除目录项。如果被解除链接的文件只出现在一个目录中，则将它从文件中删除。如果它出现在多个目录中，则只删除指定路径名的链接，依然保留其他路径名的链接。在 UNIX 中，用于删除文件的系统调用就是 unlink。

## 文件系统的实现
### 文件系统布局
文件系统存储在磁盘中。大部分的磁盘能够划分出一到多个分区，叫做磁盘分区(disk partitioning) 或者是磁盘分片(disk slicing)。每个分区都有独立的文件系统，每块分区的文件系统可以不同。磁盘的 0 号分区称为 主引导记录(Master Boot Record, MBR)，用来引导(boot) 计算机。在 MBR 的结尾是分区表(partition table)。每个分区表给出每个分区由开始到结束的地址。

当计算机开始引 boot 时，BIOS 读入并执行 MBR。

### 引导块



----------------------------------------------------------------------
# 操作系统面试集锦
## 虚机和容器的区别
虚机拥有自己独立的基础架构和系统，拥有自己的内核，虚机可以减少在服务器设备上的支出，可以利用一个物理服务器资源切分成多个独立的虚拟机来完成很多工作。虚机的系统完全相互独立，可以在不同的虚机里安装不同的系统环境。并且虚机和主机操作系统隔离，是进行实验和开发应用程序的安全场所。劣势：虚机可能占用主机的大量系统资源，在虚拟服务器上运行单个应用程序可能会增加很多的RAM和CPU的资源消耗。并且迁移虚机上的应用程序也可能很复杂，必须同时迁移应用程序和操作系统。同时在创建虚机是，系统管理程序需要分配专用于VM的硬件资源。

容器不依赖操作系统以及应用程序的环境，是通过linux的namespaces和cgroups技术对应用程序进程进行隔离和限制。但是多个容器共用同一个宿主的内核，只是运行在宿主机上的一种特殊的进程。

## 容器如何工作 cgroup namespace chroot（change root)
namespace的作用是隔离，让应用进程只能看到该namespace内的世界，而cgroups的作用是限制，给这个container的世界围上了一圈看不见的墙。在容器进程启动之前会通过pivot——root或者chroot系统调用改变进程的文件系统从而重新挂载他的整个根目录，这里还有一个rootfs根文件系统，这个的存在就能够使之前的挂在对宿主机不可见。这个挂载在容器的根目录上，用来为容器进程提供隔离后执行环境的文件系统，也就是所谓的容器镜像。但是这个根文件系统只是一个操作系统所包含的文件、配置和目录，并不包括操作系统的内核。所以，同一机器上所有容器都共享宿主机操作系统的内核。-->缺陷：如果容器里的应用程序需要配置内核参数或者跟内核进行直接的交互，这些都是操作了宿主机操作系统的内核，对于该机器的所有容器来说是一个全局变量，牵一发而动全身。  优点：由于根文件系统里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着应用以及运行所需要的所有依赖，都封装在一起了，这就赋予了容器的一致性：无论在本地、云端或者任何地方的机器上，用户只要解压打包好的容器镜像，这个应用程序运行所需要的完整的执行环境就可以被重现出来。

## 容器的优势
容器占用的大小比虚机小很多，可以轻松限制容器的内存和CPU使用率。与部署应用需要部署整个操作系统的虚机相比，容器非常轻巧并且启动迅速，可以快速扩展容器并添加相同的容易。 并且容器对于持续集成和持续部署（ci/cd）的实施也是很好的选择。可以通过在开发人员之间分发和合并镜像来促进协作开发。

## 容器的劣势
容器无法提供与虚机相同的安全性和稳定性，由于共享主机的内核，因此不能像虚机一样完全隔离。 容器是进程级别的隔离，一个容器可以通过影响主机内核的稳定性；来影响其他容器。

## cicd 持续集成 持续发布 jenkins git pipeline
cicd其实就是一个流程，一个管道，用于实现应用开发中的高度持续自动化和持续监控。

持续集成注重将各个开发者的工作集成到一个代码仓库中，目的是尽早发现集成错误，使团队更加紧密结合，更好的协作。持续交付的目的是最小化部署或发布过程中团队固有的摩擦，能够将构建部署的每个步骤自动化，以便任何时刻都能安全的完成代码发布。持续部署是一种更高程度的自动化，无论何时代码有较大改动，都会自动进行构建或者部署。 这三个阶段都是交付流水线的一部分。

### jenkins多环境CI/CD架构设计
- 支持多分支、多环境、多项目、多套配置文件、多编程语言
- 支持一键构建、集群发布
- 支持一键回滚历史版本
- 快捷配置添加新的部署项目
- 支持多个项目使用同一个job发布或回滚
- 另外：也可以根据需要加入gitlab自动触发构建、自动化测试、钉钉通知、邮箱通知等需求

架构设计
CICD架构图
CICD过程主要在两个局域网中执行：构建服务器(开发内网)和部署服务器(生产内网)

自动触发CICD还是手动触发CICD？我认为：

开发环境采用手动触发：因为对于开发环境，提交代码比较频繁，而且有时候提交到git也并不想触发CICD。可以采取每晚定时自动触发CICD，便于异常代码及时抛出。
测试环境采用自动触发：因为测试代码的 git 分支合并是有条件限制的，合并频率比较少。
生产环境采用手动触发：因为生产环境的发布，有严控发布时间的，手动触发控制力强。

## 进程和线程以及协程的区别
Cpu读取硬盘中的程序到内存中，这个在内存中的可执行程序就叫做进程，如果一个程序多次读取到内存中，就变成了多个独立的进程。内存中任何一个地方都有相应的地址方便访问，而在内存中的每个进程自己内部都有一个虚拟独立的地址空间，在进程内就可以根据虚拟地址进行访问。而进程间是如何访问的呢？ 首先进程是程序执行的完整单位，所以大部分时间都是在进程内，那进程间就需要通信，ipc，这可能就需要进行系统调用。每个进程都以为自己独占着整个内存，不需要关心其他的进程的实际位置，这样就把进程很好的分割开了

每个进程首先 有加载的程序，通常只有一个程序计数器记录当前程序执行的位置，会按照程序顺序计算，这里的一个执行流就是一个线程，如果有多个线程的话，就会有多个程序计数器，每个线程独自运行，除此以外，每个线程还会有寄存器、堆栈等程序运行时的状态信息。同时，线程间会共享地址空间、全局变量、打开的文件等等信息。

那为什么在进程中还需要有更小的“进程”--线程呢？ 
我们假设有一个文档编辑器，也就是一个进程，存放着相应的程序和文档，现在用户在第一行末打了一个回车，那我们就需要交互的程序来接受键盘的按下事件，然后布局的程序需要将文字重新计算位置再把它们渲染出来，另外每隔一段时间需要写入的程序来保存文档到硬盘中，这个时候这三个程序最好是能够并行执行，但他们又需要访问修改同一个文档，所以肯定是在同一个进程中，所以这个时候需要更轻量级的线程：交互线程、渲染线程和保存线程。

线程是并行的最小单位，假如只有单核CPU的话，那么一次只能执行一个线程，所以就需要对每个线程轮流执行，每次单个计算的时间就成为了一个CPU时间片，实际只有几十毫秒，用户感觉不到，所以1s内相当于是并行的。存在等待CPU的时候就是就绪状态，一旦CPU过来执行，就会转为运行状态，当CPU转而执行其他线程时，线程就又变成就绪状态，假如线程正在执行中，程序向硬盘发送访问请求，然后等待，这时CPU就变成空转了，所以线程变成阻塞状态，CPU转而执行其他线程，等到硬盘的数据回复，线程从阻塞态转变成就绪状态，等待CPU的再次光临。

进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。

协程是一种用户态的轻量级线程，协程的调度完全由用户控制，协程是控制了内部的时间片给对应的函数而改变不了CPU给的外部时间片。

1、多进程一般使用multiprocessing库，来利用多核CPU，主要是用在CPU密集型的程序上，当然生产者消费者这种也可以使用。多进程的优势就是一个子进程崩溃并不会影响其他子进程和主进程的运行，但缺点就是不能一次性启动太多进程，会严重影响系统的资源调度，特别是CPU使用率和负载。

2、多线程一般是使用threading库，完成一些IO密集型并发操作。多线程的优势是切换快，资源消耗低，但一个线程挂掉则会影响到所有线程，所以不够稳定。

3、协程一般是使用gevent库

总结一下就是IO密集型一般使用多线程或者多进程，CPU密集型一般使用多进程，强调非阻塞异步并发的一般都是使用协程，当然有时候也是需要多进程线程池结合的，或者是其他组合方式。

## 地址空间管理

## 内存管理

## 系统调用
### 原理
系统有用户态和内存态，当用户需要调用由内核态内提供的程序时，就需要通过系统调用才能实现。一般的，进程是不能访问内核的。它不能访问内核所占内存空间也不能调用内核函数。这个是由CPU硬件决定的，也就是保护模式。系统调用就是一个例外，原理是进程先用适当的值填充寄存器，然后调用一个特殊的指令，这个指令会跳到一个事先定义的内核中的一个位置(当然，这个位置是用户进程可读但是不可写的)。硬件知道一旦你跳到这个位置，你就不是在限制模式下运行的用户，而是作为操作系统的内核--所以你就可以为所欲为。进程可以跳转到的内核位置叫做sysem_call。这个过程检查系统调用号，这个号码告诉内核进程请求哪种服务。然后，它查看系统调用表(sys_call_table)找到所调用的内核函数入口地址。接着，就调用函数，等返回后，做一些系统检查，最后返回到进程(或到其他进程，如果这个进程时间用尽)。

网络相关的都在内核层

### 如何进行系统调用？
Linux系统调用列表
https://www.huaweicloud.com/articles/3aa84d6af3129d6798168a162d5124c8.html
- 进程控制
fork 创建一个新进程
clone 按指定条件创建子进程
execve 运行可执行文件
exit 中止进程
_exit 立即中止当前进程
getdtablesize 进程所能打开的最大文件数
getpid 获取进程标识号
getpriority 获取调度优先级
ptrace 进程跟踪
- 文件系统控制
1. 读写操作
open 打开文件

creat 创建新文件

close 关闭文件描述字

read 读文件

write 写文件
2. 文件系统操作
access 确定文件的可存取性

chdir 改变当前工作目录
chmod 改变文件方式
chown 改变文件的属主或用户组
chroot 改变根目录
stat 取文件状态信息
statfs 取文件系统信息
mkdir 创建目录

mknod 创建索引节点

rmdir 删除目录

rename 文件改名

link 创建链接

- 系统控制
sysinfo 取得系统信息
init_module 初始化模块

- 内存管理

- 网络管理
- 用户管理
- 进程间通信
- 消息
- 管道
- 信号量
- 共享内存

## Nginx
Nginx是一种Web服务器，基于REST架构风格，通过HTTP协议提供各种网络服务。可以支持百万级别的TCP里拦截。是一个跨平台服务器，可以运行在不同操作系统上。

Nginx是高性能的反向代理。

什么是反向代理？
反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。
反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。
反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。
如果请求数量比较大，单个服务器解决不了就要增加服务器的数量，然后把请求分到各个服务器上，这个时候就要用到负载均衡。Upstream 指定后端服务器地址列表，在 server 中拦截响应请求，并将请求转发到 Upstream 中配置的服务器列表。但这只是指定了 nginx 需要转发的服务端列表，并没有指定分配策略。默认情况下采用的是轮询策略。

Nginx支持的负载均衡算法有：
- weight轮询(默认，常用)：接收到的请求按照权重分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。这种方式下，可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。ip_hash（常用）：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。
- fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块。url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

动静分离
为了加快服务器的解析速度，可以把动态页面和静态页面交给不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。

### 为什么选择Nginx
- Nginx采用了七层负载均衡 应用层的东西都在用户态
- 采用了IO多路复用epoll
- 轻量级：功能模块少-仅保留了HTTP需要的模块，其他都用插件方式，后天添加； 代码模块化-更适合二次开发
- CPU亲和：把CPU核心和Nginx工作进程绑定，把每个worker进程固定在一个CPU上执行，减少切换CPU的cache miss，从而提高性能


## 负载均衡 七层负载和四层负载
如果请求数量比较大，单个服务器解决不了就要增加服务器的数量，然后把请求分到各个服务器上，这个时候就要用到负载均衡。Upstream 指定后端服务器地址列表，在 server 中拦截响应请求，并将请求转发到 Upstream 中配置的服务器列表。

## IO 多路复用 epoll， poll

## 集群

## Kubernetes k8s
知道k8s是一个docker 容器编排工具, 相当于容器在集群化的调度解决方案
嗯对 类似于利用jenkins 发布创建容器这种, k8s多了个管理功能, 包括网络这种

## 监控 普罗米修斯+grafana thanos聚合多个普罗米修斯

## 系统优化

## troubleshooting



## 计网  


## Cookie，session，token

## 打开网站经过的过程 DNS解析
DNS 你知道这个东西是什么就行, 实际上就是把一个域名翻译成IP用的, 俗称解析. 因为这个考点有的时候可能会问你打开会经历什么过程.一般来说简化下来是这几步
1. DNS 解析域名成目标IP
2. 从本机发起到目标IP的TCP请求
3. 建立TCP连接后, 开始HTTP协议通信
