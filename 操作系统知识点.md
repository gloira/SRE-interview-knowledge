# 操作系统
## 基本定义
操作系统提供了四种抽象模型：
 - 文件：对 I/O 设备的抽象
 - 虚拟内存：对程序存储器的抽象
 - 进程：对一个正在运行程序的抽象
 - 虚拟机：对整个操作系统的抽象
 
我们程序员不会直接和这些硬件打交道，并且每位程序员不可能会掌握所有计算机系统的细节。
所以计算机科学家在硬件的基础之上，安装了一层软件，这层软件能够根据用户输入的指令达到控制硬件的效果，从而满足用户的需求，这样的软件称为 操作系统，它的任务就是为用户程序提供一个更好、更简单、更清晰的计算机模型。也就是说，操作系统相当于是一个中间层，为用户层和硬件提供各自的借口，屏蔽了不同应用和硬件之间的差异，达到统一标准的作用。
![image](https://user-images.githubusercontent.com/81898811/113501580-cfbf1800-9558-11eb-9d8b-e6272f2e9b0e.png)

## 计算机硬件
5个重要组成部分：
- 运算器
- 控制器
--> 运算器和控制及组成了CPU
- 存储器：一种是主存，也就是内存，它是 CPU 主要交互对象，还有一种是外存，比如硬盘软盘等
- 输入设备
- 输出设备
![image](https://user-images.githubusercontent.com/81898811/113501643-5c69d600-9559-11eb-91ff-421845e7629e.png)

CPU(处理器)可能执行简单操作的几个步骤：
- 加载(Load)：从主存中拷贝一个字节或者一个字到内存中，覆盖寄存器先前的内容
- 存储(Store)：将寄存器中的字节或字复制到主存储器中的某个位置，从而覆盖该位置的先前内容
- 操作(Operate)：把两个寄存器的内容复制到 ALU(Arithmetic logic unit)。把两个字进行算术运算，并把结果存储在寄存器中，重写寄存器先前的内容。算术逻辑单元（ALU）是对数字二进制数执行算术和按位运算的组合数字电子电路。
- 跳转(jump)：从指令中抽取一个字，把这个字复制到程序计数器(PC) 中，覆盖原来的值

## 进程
操作系统中最核心的概念就是 进程，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。
### 进程模型
一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。
![image](https://user-images.githubusercontent.com/81898811/113501779-748e2500-955a-11eb-8ba9-3d6d892c0b43.png)
如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。
![image](https://user-images.githubusercontent.com/81898811/113501801-8bcd1280-955a-11eb-8258-f12c62576563.png)
在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。

从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正运行。
![image](https://user-images.githubusercontent.com/81898811/113502193-4827d800-955d-11eb-9742-d24af7e12422.png)
因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），每一个核也只能一次运行一个线程。

由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。

这里的关键思想是认识到一个进程所需的条件，进程是某一类特定活动的总和，它有程序、输入输出以及状态。

### 进程的创建
在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 fork。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。

在 Windows 中，情况正相反，一个简单的 Win32 功能调用 CreateProcess，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的。

### 进程的终止
- 正常退出(自愿的) ： 多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 exit ，在 Windows 中是 ExitProcess。
- 错误退出(自愿的)：比如执行一条不存在的命令，于是编译器就会提醒并退出。
- 严重错误(非自愿的)
- 被其他进程杀死(非自愿的) ： 某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess（注意不是系统调用）。

### 进程的层次结构
在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。
#### UNIX进程体系
在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。
#### Windows进程体系
相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。

### 进程状态
尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。当一个进程开始运行时，它可能会经历下面这几种状态
![image](https://user-images.githubusercontent.com/81898811/113502396-b8832900-955e-11eb-89d2-c282608c3094.png)
- 运行态，运行态指的就是进程实际占用 CPU 时间片运行时
- 就绪态，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态
- 阻塞态，除非某种外部事件发生，否则进程不能运行

### 进程的实现
操作系统为了执行进程间的切换，会维护着一张表，这张表就是 进程表(process table)。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息。
![image](https://user-images.githubusercontent.com/81898811/113502508-4ced8b80-955f-11eb-9a3d-5e0dafa8c333.png)
一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。

## 线程
在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。
### 线程的使用
为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答
- 多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的
- 线程要比进程更轻量级，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。
- 第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度

### 经典的线程模型
进程中拥有一个执行的线程，通常简写为 线程(thread)。线程会有程序计数器，用来记录接着要执行哪一条指令；线程实际是 CPU 上调度执行的实体。
下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行
![image](https://user-images.githubusercontent.com/81898811/113502911-82937400-9561-11eb-83e0-5cf253183c44.png)
下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。
![image](https://user-images.githubusercontent.com/81898811/113502942-9dfe7f00-9561-11eb-9891-2f88e9263bd2.png)
线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，因此一个线程可以读取、写入甚至擦除另一个线程的堆栈。线程之间除了共享同一内存空间外，还具有如下不同的内容
![image](https://user-images.githubusercontent.com/81898811/113503103-51677380-9562-11eb-9d9e-d193eb19893c.png)
上图左边的是同一个进程中每个线程共享的内容，上图右边是每个线程中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。

线程之间的状态转换和进程之间的状态转换是一样的。

每个线程都会有自己的堆栈，如下图所示
![image](https://user-images.githubusercontent.com/81898811/113503127-6ba15180-9562-11eb-8c85-4492bf1485d2.png)

### 线程系统调用
进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 thread_create）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。

当一个线程完成工作后，可以通过调用一个函数（比如 thread_exit）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 thread_join ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。

另一个常见的线程是调用 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。

### 线程实现
主要三种方式：
- 在用户空间中实现线程；
- 在内核空间中实现线程；
- 在用户和内核空间中混合实现线程。

#### 在用户空间中实现线程；
第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构
![image](https://user-images.githubusercontent.com/81898811/113503187-cdfa5200-9562-11eb-8173-89696eb413ad.png)
线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程： pthread_create, pthread_exit, pthread_join 和 pthread_yield。

#### 在内核中实现线程
当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。
![image](https://user-images.githubusercontent.com/81898811/113503212-f5511f00-9562-11eb-8cbe-497b8210d7bd.png)
内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。

所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。

#### 混合实现
结合用户空间和内核空间的优点，设计人员采用了一种内核级线程的方式，然后将用户级线程与某些或者全部内核线程多路复用起来
![image](https://user-images.githubusercontent.com/81898811/113503249-377a6080-9563-11eb-9c23-a38243b79d24.png)
在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。

## 进程间通信
进程是需要频繁的和其他进程进行交流的。下面我们会一起讨论有关 进程间通信(Inter Process Communication, IPC) 的问题。大致来说，进程间的通信机制可以分为 6 种
![image](https://user-images.githubusercontent.com/81898811/113503275-609af100-9563-11eb-8c56-c3388c0751d2.png)

### 信号 signal
信号是 UNIX 系统最先开始使用的进程间通信机制，因为 Linux 是继承于 UNIX 的，所以 Linux 也支持信号机制，通过向一个或多个进程发送异步事件信号来实现，信号可以从键盘或者访问不存在的位置等地方产生；信号通过 shell 将任务发送给子进程。

你可以在 Linux 系统上输入 kill -l 来列出系统使用的信号，下面是我提供的一些信号
![image](https://user-images.githubusercontent.com/81898811/113503353-e9b22800-9563-11eb-906a-0643bfa836f8.png)
进程可以选择忽略发送过来的信号，但是有两个是不能忽略的：SIGSTOP 和 SIGKILL 信号。SIGSTOP 信号会通知当前正在运行的进程执行关闭操作，SIGKILL 信号会通知当前进程应该被杀死。除此之外，进程可以选择它想要处理的信号，进程也可以选择阻止信号，如果不阻止，可以选择自行处理，也可以选择进行内核处理。如果选择交给内核进行处理，那么就执行默认处理。

操作系统会中断目标程序的进程来向其发送信号、在任何非原子指令中，执行都可以中断，如果进程已经注册了新号处理程序，那么就执行进程，如果没有注册，将采用默认处理的方式。

### 管道 pipe
Linux 系统中的进程可以通过建立管道 pipe 进行通信

在两个进程之间，可以建立一个通道，一个进程向这个通道里写入字节流，另一个进程从这个管道中读取字节流。管道是同步的，当进程尝试从空管道读取数据时，该进程会被阻塞，直到有可用数据为止。shell 中的管线 pipelines 就是用管道实现的，当 shell 发现输出

``` sort <f | head ```

它会创建两个进程，一个是 sort，一个是 head，sort，会在这两个应用程序之间建立一个管道使得 sort 进程的标准输出作为 head 程序的标准输入。sort 进程产生的输出就不用写到文件中了，如果管道满了系统会停止 sort 以等待 head 读出数据
管道实际上就是``` | ```，两个应用程序不知道有管道的存在，一切都是由 shell 管理和控制的。

### 共享内存 shared memory
两个进程之间还可以通过共享内存进行进程间通信，其中两个或者多个进程可以访问公共内存空间。两个进程的共享工作是通过共享内存完成的，一个进程所作的修改可以对另一个进程可见(很像线程间的通信)。

在使用共享内存前，需要经过一系列的调用流程，流程如下

- 创建共享内存段或者使用已创建的共享内存段 ```shmget()```
- 将进程附加到已经创建的内存段中 ```shmat()```
- 从已连接的共享内存段分离进程 ```shmdt()```
- 对共享内存段执行控制操作 ```shmctl()```

### 先入先出队列 FIFO
先入先出队列 FIFO 通常被称为 命名管道(Named Pipes)，命名管道的工作方式与常规管道非常相似，但是确实有一些明显的区别。未命名的管道没有备份文件：操作系统负责维护内存中的缓冲区，用来将字节从写入器传输到读取器。一旦写入或者输出终止的话，缓冲区将被回收，传输的数据会丢失。相比之下，命名管道具有支持文件和独特 API ，命名管道在文件系统中作为设备的专用文件存在。当所有的进程通信完成后，命名管道将保留在文件系统中以备后用。命名管道具有严格的 FIFO 行为

写入的第一个字节是读取的第一个字节，写入的第二个字节是读取的第二个字节，依此类推。

### 消息队列 Message Queue
一听到消息队列这个名词你可能不知道是什么意思，消息队列是用来描述内核寻址空间内的内部链接列表。可以按几种不同的方式将消息按顺序发送到队列并从队列中检索消息。每个消息队列由 IPC 标识符唯一标识。消息队列有两种模式，一种是严格模式， 严格模式就像是 FIFO 先入先出队列似的，消息顺序发送，顺序读取。还有一种模式是 非严格模式，消息的顺序性不是非常重要。

### 套接字 Socket
还有一种管理两个进程间通信的是使用``` socket```，socket 提供端到端的双相通信。一个套接字可以与一个或多个进程关联。就像管道有命令管道和未命名管道一样，套接字也有两种模式，套接字一般用于两个进程之间的网络通信，网络套接字需要来自诸如```TCP（传输控制协议）```或较低级别```UDP（用户数据报协议）```等基础协议的支持。

套接字有以下几种分类

- 顺序包套接字(Sequential Packet Socket)： 此类套接字为最大长度固定的数据报提供可靠的连接。此连接是双向的并且是顺序的。
- 数据报套接字(Datagram Socket)：数据包套接字支持双向数据流。数据包套接字接受消息的顺序与发送者可能不同。
- 流式套接字(Stream Socket)：流套接字的工作方式类似于电话对话，提供双向可靠的数据流。
- 原始套接字(Raw Socket)： 可以使用原始套接字访问基础通信协议

## 调度
当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程/线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程/线程可以运行。操作系统中有一个叫做 ```调度程序(scheduler)``` 的角色存在，它就是做这件事儿的，该程序使用的算法叫做``` 调度算法(scheduling algorithm)```。

### 调度算法的分类
毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境
- 批处理(Batch) : 商业领域
- 交互式(Interactive)： 交互式用户环境
- 实时(Real time)

### 批处理中的调度
#### 先来先服务
最简单的非抢占式调度算法的设计就是```先来先服务(first-come,first-serverd)```。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。

这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。

#### 最短作业优先
批处理中，第二种调度算法是```最短作业优先(Shortest Job First)```，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法

需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。

#### 最短剩余时间优先
最短作业优先的抢占式版本被称作为 ```最短剩余时间优先(Shortest Remaining Time Next) ```算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。

### 交互式系统中的调度
#### 轮询制度
一种最古老、最简单、最公平并且最广泛使用的算法就是 轮询算法(round-robin)。每个进程都会被分配一个时间段，称为时间片(quantum)，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。
![image](https://user-images.githubusercontent.com/81898811/113503976-d1440c80-9567-11eb-9ae1-fe094eb863af.png)

#### 优先级调度
轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了```优先级调度(priority scheduling)```
它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。

#### 多级队列
最早使用优先级调度的系统是 CTSS(Compatible TimeSharing System)。CTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。

#### 最短进程优先
最短进程优先是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。

#### 保证调度
一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。

#### 彩票调度
对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 彩票调度(lottery scheduling)算法。

其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。

#### 公平分享调度
到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。

为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。

### 实时系统中的调度
实时系统(real-time) 是一个时间扮演了重要作用的系统。实时系统可以分为两类，硬实时(hard real time) 和 软实时(soft real time) 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。

## 内存管理
![image](https://user-images.githubusercontent.com/81898811/113504248-6e537500-9569-11eb-9d7c-bfd7e0a3558a.png)

## 地址空间（空间管理）
如果要使多个应用程序同时运行在内存中，必须要解决两个问题：```保护```和 ```重定位```。第一种解决方式是用```保护密钥标记内存块```，并将执行过程的密钥与提取的每个存储字的密钥进行比较。这种方式只能解决第一种问题（破坏操作系统），但是不能解决多进程在内存中同时运行的问题。

还有一种更好的方式是创造一个存储器抽象：```地址空间(the address space)```。就像进程的概念创建了一种抽象的 CPU 来运行程序，地址空间也创建了一种抽象内存供程序使用。

#### 基址寄存器和变址寄存器
最简单的办法是使用动态重定位(dynamic relocation)技术，它就是通过一种简单的方式将每个进程的地址空间映射到物理内存的不同区域。还有一种方式是使用基址寄存器和变址寄存器。
- 基址寄存器：存储数据内存的起始位置
- 变址寄存器：存储应用程序的长度。
每当进程引用内存以获取指令或读取、写入数据时，CPU 都会自动将```基址值```添加到进程生成的地址中，然后再将其发送到内存总线上。同时，它检查程序提供的地址是否大于或等于变址寄存器 中的值。如果程序提供的地址要超过```变址寄存器```的范围，那么会产生错误并中止访问。

### 交换技术
在程序运行过程中，经常会出现内存不足的问题。

针对上面内存不足的问题，提出了两种处理方式：最简单的一种方式就是```交换(swapping)```技术，即把一个进程完整的调入内存，然后再内存中运行一段时间，再把它放回磁盘。空闲进程会存储在磁盘中，所以这些进程在没有运行时不会占用太多内存。另外一种策略叫做```虚拟内存(virtual memory)```，虚拟内存技术能够允许应用程序部分的运行在内存中。下面我们首先先探讨一下交换

#### 交换过程
![image](https://user-images.githubusercontent.com/81898811/113504424-97283a00-956a-11eb-970b-4087890a1542.png)
刚开始的时候，只有进程 A 在内存中，然后从创建进程 B 和进程 C 或者从磁盘中把它们换入内存，然后在图 d 中，A 被换出内存到磁盘中，最后 A 重新进来。因为图 g 中的进程 A 现在到了不同的位置，所以在装载过程中需要被重新定位，或者在交换程序时通过软件来执行；或者在程序执行期间通过硬件来重定位。基址寄存器和变址寄存器就适用于这种情况。
![image](https://user-images.githubusercontent.com/81898811/113504437-a7d8b000-956a-11eb-9e28-4def0f4003f4.png)

交换在内存创建了多个 空闲区(hole)，内存会把所有的空闲区尽可能向下移动合并成为一个大的空闲区。这项技术称为内存紧缩(memory compaction)。但是这项技术通常不会使用，因为这项技术会消耗很多 CPU 时间。

### 空闲内存管理
在进行内存动态分配时，操作系统必须对其进行管理。大致上说，有两种监控内存使用的方式

- 位图(bitmap)
- 空闲列表(free lists)

#### 使用位图的存储管理
使用位图方法时，内存可能被划分为小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用（或者相反）。一块内存区域和其对应的位图如下
![image](https://user-images.githubusercontent.com/81898811/113504508-187fcc80-956b-11eb-9f92-c8b0bd240ecf.png)
位图提供了一种简单的方法在固定大小的内存中跟踪内存的使用情况，因为位图的大小取决于内存和分配单元的大小。这种方法有一个问题是，当决定为把具有 k 个分配单元的进程放入内存时，内容管理器(memory manager) 必须搜索位图，在位图中找出能够运行 k 个连续 0 位的串。在位图中找出制定长度的连续 0 串是一个很耗时的操作，这是位图的缺点。（可以简单理解为在杂乱无章的数组中，找出具有一大长串空闲的数组单元）

#### 使用链表进行管理
另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表，段会包含进程或者是两个进程的空闲区域。可用上面的图 c 来表示内存的使用情况。链表中的每一项都可以代表一个 空闲区(H) 或者是进程(P)的起始标志，长度和下一个链表项的位置。

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以为创建的进程（或者从磁盘中换入的进程）分配内存。我们先假设内存管理器知道应该分配多少内存，最简单的算法是使用 首次适配(first fit)。内存管理器会沿着段列表进行扫描，直到找个一个足够大的空闲区为止。 除非空闲区大小和要分配的空间大小一样，否则将空闲区分为两部分，一部分供进程使用；一部分生成新的空闲区。首次适配算法是一种速度很快的算法，因为它会尽可能的搜索链表。

首次适配的一个小的变体是 下次适配(next fit)。它和首次匹配的工作方式相同，只有一个不同之处那就是下次适配在每次找到合适的空闲区时就会记录当时的位置，以便下次寻找空闲区时从上次结束的地方开始搜索，而不是像首次匹配算法那样每次都会从头开始搜索。

另外一个著名的并且广泛使用的算法是 最佳适配(best fit)。最佳适配会从头到尾寻找整个链表，找出能够容纳进程的最小空闲区。

## 虚拟内存
尽管基址寄存器和变址寄存器用来创建地址空间的抽象，但是这有一个其他的问题需要解决：管理软件的不断增大(managing bloatware)。虚拟内存的基本思想是，每个程序都有自己的地址空间，这个地址空间被划分为多个称为```页面(page)```的块。每一页都是连续的地址范围。这些页被映射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，硬件会立刻执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令。

### 分页
大部分使用虚拟内存的系统中都会使用一种 分页(paging) 技术。在任何一台计算机上，程序会引用使用一组内存地址。当程序执行

``` MOV REG,1000 ```

这条指令时，它会把内存地址为 1000 的内存单元的内容复制到 REG 中（或者相反，这取决于计算机）。地址可以通过索引、基址寄存器、段寄存器或其他方式产生。

这些程序生成的地址被称为 虚拟地址(virtual addresses) 并形成虚拟地址空间(virtual address space)，在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存中线上，读写操作都使用同样地址的物理内存。在使用虚拟内存时，虚拟地址不会直接发送到内存总线上。相反，会使用 MMU(Memory Management Unit) 内存管理单元把虚拟地址映射为物理内存地址，像下图这样
![image](https://user-images.githubusercontent.com/81898811/113504952-54686100-956e-11eb-8a7a-c3d910afd117.png)
下面这幅图展示了这种映射是如何工作的
![image](https://user-images.githubusercontent.com/81898811/113504981-7eba1e80-956e-11eb-9518-774499893e30.png)
页表给出虚拟地址与物理内存地址之间的映射关系。每一页起始于 4096 的倍数位置，结束于 4095 的位置，所以 4K 到 8K 实际为 4096 - 8191 ，8K - 12K 就是 8192 - 12287

在这个例子中，我们可能有一个 16 位地址的计算机，地址从 0 - 64 K - 1，这些是虚拟地址。然而只有 32 KB 的物理地址。所以虽然可以编写 64 KB 的程序，但是程序无法全部调入内存运行，在磁盘上必须有一个最多 64 KB 的程序核心映像的完整副本，以保证程序片段在需要时被调入内存。

### 页表
虚拟页号可作为页表的索引用来找到虚拟页中的内容。由页表项可以找到页框号（如果有的话）。然后把页框号拼接到偏移量的高位端，以替换掉虚拟页号，形成物理地址。
因此，页表的目的是把虚拟页映射到页框中。从数学上说，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。
#### 页表项的结构
下面我们探讨一下页表项的具体结构，上面你知道了页表项的大致构成，是由页框号和在/不在位构成的，现在我们来具体探讨一下页表项的构成
![image](https://user-images.githubusercontent.com/81898811/113505043-0011b100-956f-11eb-804d-b59d7cd84fca.png)
页表项的结构是与机器相关的，但是不同机器上的页表项大致相同。上面是一个页表项的构成，不同计算机的页表项可能不同，但是一般来说都是 32 位的。页表项中最重要的字段就是页框号(Page frame number)。毕竟，页表到页框最重要的一步操作就是要把此值映射过去。下一个比较重要的就是在/不在位，如果此位上的值是 1，那么页表项是有效的并且能够被使用。如果此值是 0 的话，则表示该页表项对应的虚拟页面不在内存中，访问该页面会引起一个缺页异常(page fault)。

保护位(Protection) 告诉我们哪一种访问是允许的，啥意思呢？最简单的表示形式是这个域只有一位，0 表示可读可写，1 表示的是只读。

修改位(Modified) 和 访问位(Referenced) 会跟踪页面的使用情况。当一个页面被写入时，硬件会自动的设置修改位。修改位在页面重新分配页框时很有用。如果一个页面已经被修改过（即它是 脏 的），则必须把它写回磁盘。如果一个页面没有被修改过（即它是 干净的），那么重新分配时这个页框会被直接丢弃，因为磁盘上的副本仍然是有效的。这个位有时也叫做 脏位(dirty bit)，因为它反映了页面的状态。

访问位(Referenced) 在页面被访问时被设置，不管是读还是写。这个值能够帮助操作系统在发生缺页中断时选择要淘汰的页。不再使用的页要比正在使用的页更适合被淘汰。这个位在后面要讨论的页面置换算法中作用很大。

最后一位用于禁止该页面被高速缓存，这个功能对于映射到设备寄存器还是内存中起到了关键作用。通过这一位可以禁用高速缓存。具有独立的 I/O 空间而不是用内存映射 I/O 的机器来说，并不需要这一位。

## 页面置换算法

### 最优页面置换算法
最优的页面置换算法的工作流程如下：在缺页中断发生时，这些页面之一将在下一条指令（包含该指令的页面）上被引用。其他页面则可能要到 10、100 或者 1000 条指令后才会被访问。每个页面都可以用在该页首次被访问前所要执行的指令数作为标记。

最优化的页面算法表明应该标记最大的页面。如果一个页面在 800 万条指令内不会被使用，另外一个页面在 600 万条指令内不会被使用，则置换前一个页面，从而把需要调入这个页面而发生的缺页中断推迟。计算机也像人类一样，会把不愿意做的事情尽可能的往后拖。

这个算法最大的问题时无法实现。当缺页中断发生时，操作系统无法知道各个页面的下一次将在什么时候被访问。这种算法在实际过程中根本不会使用。

### 最近未使用页面置换算法 NRU
为了能够让操作系统收集页面使用信息，大部分使用虚拟地址的计算机都有两个状态位，R 和 M，来和每个页面进行关联。每当引用页面（读入或写入）时都设置 R，写入（即修改）页面时设置 M，这些位包含在每个页表项中，就像下面所示
![image](https://user-images.githubusercontent.com/81898811/113505043-0011b100-956f-11eb-804d-b59d7cd84fca.png)
因为每次访问时都会更新这些位，因此由硬件来设置它们非常重要。一旦某个位被设置为 1，就会一直保持 1 直到操作系统下次来修改此位。

如果硬件没有这些位，那么可以使用操作系统的缺页中断和时钟中断机制来进行模拟。当启动一个进程时，将其所有的页面都标记为不在内存；一旦访问任何一个页面就会引发一次缺页中断，此时操作系统就可以设置 R 位(在它的内部表中)，修改页表项使其指向正确的页面，并设置为 READ ONLY 模式，然后重新启动引起缺页中断的指令。如果页面随后被修改，就会发生另一个缺页异常。从而允许操作系统设置 M 位并把页面的模式设置为 READ/WRITE。

可以用 R 位和 M 位来构造一个简单的页面置换算法：当启动一个进程时，操作系统将其所有页面的两个位都设置为 0。R 位定期的被清零（在每个时钟中断）。用来将最近未引用的页面和已引用的页面分开。

当出现缺页中断后，操作系统会检查所有的页面，并根据它们的 R 位和 M 位将当前值分为四类：

第 0 类：没有引用 R，没有修改 M
第 1 类：没有引用 R，已修改 M
第 2 类：引用 R ，没有修改 M
第 3 类：已被访问 R，已被修改 M
尽管看起来好像无法实现第一类页面，但是当第三类页面的 R 位被时钟中断清除时，它们就会发生。时钟中断不会清除 M 位，因为需要这个信息才能知道是否写回磁盘中。清除 R 但不清除 M 会导致出现一类页面。

NRU(Not Recently Used) 算法从编号最小的非空类中随机删除一个页面。此算法隐含的思想是，在一个时钟内（约 20 ms）淘汰一个已修改但是没有被访问的页面要比一个大量引用的未修改页面好，NRU 的主要优点是易于理解并且能够有效的实现。

### 先进先出页面置换算法 FIFO
另一种开销较小的方式是使用 FIFO(First-In,First-Out) 算法，这种类型的数据结构也适用在页面置换算法中。由操作系统维护一个所有在当前内存中的页面的链表，最早进入的放在表头，最新进入的页面放在表尾。在发生缺页异常时，会把头部的页移除并且把新的页添加到表尾。

### 第二次机会页面置换算法
我们上面学到的 FIFO 链表页面有个缺陷，那就是出链和入链并不会进行 check 检查，这样就会容易把经常使用的页面置换出去，为了避免这一问题，我们对该算法做一个简单的修改：我们检查最老页面的 R 位，如果是 0 ，那么这个页面就是最老的而且没有被使用，那么这个页面就会被立刻换出。如果 R 位是 1，那么就清除此位，此页面会被放在链表的尾部，修改它的装入时间就像刚放进来的一样。然后继续搜索。

这种算法叫做 第二次机会(second chance)算法，就像下面这样，我们看到页面 A 到 H 保留在链表中，并按到达内存的时间排序。

假设缺页异常发生在时刻 20 处，这时最老的页面是 A ，它是在 0 时刻到达的。如果 A 的 R 位是 0，那么它将被淘汰出内存，或者把它写回磁盘（如果它已经被修改过），或者只是简单的放弃（如果它是未被修改过）。另一方面，如果它的 R 位已经设置了，则将 A 放到链表的尾部并且重新设置装入时间为当前时刻（20 处），然后清除 R 位。然后从 B 页面开始继续搜索合适的页面。

寻找第二次机会的是在最近的时钟间隔中未被访问过的页面。如果所有的页面都被访问过，该算法就会被简化为单纯的 FIFO 算法。具体来说，假设图 a 中所有页面都设置了 R 位。操作系统将页面依次移到链表末尾，每次都在添加到末尾时清除 R 位。最后，算法又会回到页面 A，此时的 R 位已经被清除，那么页面 A 就会被执行出链处理，因此算法能够正常结束。

### 时钟页面置换算法
一种比较好的方式是把所有的页面都保存在一个类似钟面的环形链表中，一个表针指向最老的页面。如下图所示
![image](https://user-images.githubusercontent.com/81898811/113505331-9692a200-9570-11eb-85cd-b86ae254ddb5.png)
当缺页错误出现时，算法首先检查表针指向的页面，如果它的 R 位是 0 就淘汰该页面，并把新的页面插入到这个位置，然后把表针向前移动一位；如果 R 位是 1 就清除 R 位并把表针前移一个位置。重复这个过程直到找到了一个 R 位为 0 的页面位置。了解这个算法的工作方式，就明白为什么它被称为 时钟(clokc)算法了。

### 最近最少使用页面置换算法 LRU Least Recently Used
在前面几条指令中频繁使用的页面和可能在后面的几条指令中被使用。反过来说，已经很久没有使用的页面有可能在未来一段时间内仍不会被使用。这个思想揭示了一个可以实现的算法：在缺页中断时，置换未使用时间最长的页面。这个策略称为 LRU(Least Recently Used) ，最近最少使用页面置换算法。

虽然 LRU 在理论上是可以实现的，但是从长远看来代价比较高。为了完全实现 LRU，会在内存中维护一个所有页面的链表，最频繁使用的页位于表头，最近最少使用的页位于表尾。困难的是在每次内存引用时更新整个链表。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常耗时的操作，即使使用硬件来实现也是一样的费时。

### 用软件模拟 LRU
尽管上面的 LRU 算法在原则上是可以实现的，但是很少有机器能够拥有那些特殊的硬件。上面是硬件的实现方式，那么现在考虑要用软件来实现 LRU 。一种可以实现的方案是 NFU(Not Frequently Used，最不常用)算法。它需要一个软件计数器来和每个页面关联，初始化的时候是 0 。在每个时钟中断时，操作系统会浏览内存中的所有页，会将每个页面的 R 位（0 或 1）加到它的计数器上。这个计数器大体上跟踪了各个页面访问的频繁程度。当缺页异常出现时，则置换计数器值最小的页面。

只需要对 NFU 做一个简单的修改就可以让它模拟 LRU，这个修改有两个步骤

- 首先，在 R 位被添加进来之前先把计数器右移一位；
- 第二步，R 位被添加到最左边的位而不是最右边的位。

修改以后的算法称为 ```老化(aging) ```算法，下图解释了老化算法是如何工作的。
![image](https://user-images.githubusercontent.com/81898811/113505438-6a2b5580-9571-11eb-9302-621b32a1bb3c.png)
我们假设在第一个时钟周期内页面 0 - 5 的 R 位依次是 1，0，1，0，1，1，（也就是页面 0 是 1，页面 1 是 0，页面 2 是 1 这样类推）。也就是说，在 0 个时钟周期到 1 个时钟周期之间，0，2，4，5 都被引用了，从而把它们的 R 位设置为 1，剩下的设置为 0 。在相关的六个计数器被右移之后 R 位被添加到 左侧 ，就像上图中的 a。剩下的四列显示了接下来的四个时钟周期内的六个计数器变化。

CPU正在以某个频率前进，该频率的周期称为时钟滴答或时钟周期。一个 100Mhz 的处理器每秒将接收100,000,000个时钟滴答。

当缺页异常出现时，将置换（就是移除）计数器值最小的页面。如果一个页面在前面 4 个时钟周期内都没有被访问过，那么它的计数器应该会有四个连续的 0 ，因此它的值肯定要比前面 3 个时钟周期内都没有被访问过的页面的计数器小。

这个算法与 LRU 算法有两个重要的区别：看一下上图中的 e，第三行和第五行

### 工作集时钟页面置换算法 WSCLOCK
当缺页异常发生后，需要扫描整个页表才能确定被淘汰的页面，因此基本工作集算法还是比较浪费时间的。一个对基本工作集算法的提升是基于时钟算法但是却使用工作集的信息，这种算法称为WSClock(工作集时钟)。由于它的实现简单并且具有高性能，因此在实践中被广泛应用。

与时钟算法一样，所需的数据结构是一个以页框为元素的循环列表，就像下面这样
![image](https://user-images.githubusercontent.com/81898811/113505473-abbc0080-9571-11eb-9e82-80f5839072ea.png)

 工作集时钟页面置换算法的操作：a) 和 b) 给出 R = 1 时所发生的情形；c) 和 d) 给出 R = 0 的例子

最初的时候，该表是空的。当装入第一个页面后，把它加载到该表中。随着更多的页面的加入，它们形成一个环形结构。每个表项包含来自基本工作集算法的上次使用时间，以及 R 位（已标明）和 M 位（未标明）。

与时钟算法一样，在每个缺页异常时，首先检查指针指向的页面。如果 R 位被是设置为 1，该页面在当前时钟周期内就被使用过，那么该页面就不适合被淘汰。然后把该页面的 R 位置为 0，指针指向下一个页面，并重复该算法。该事件序列化后的状态参见图 b。

现在考虑指针指向的页面 R = 0 时会发生什么，参见图 c，如果页面的使用期限大于 t 并且页面为被访问过，那么这个页面就不会在工作集中，并且在磁盘上会有一个此页面的副本。申请重新调入一个新的页面，并把新的页面放在其中，如图 d 所示。另一方面，如果页面被修改过，就不能重新申请页面，因为这个页面在磁盘上没有有效的副本。为了避免由于调度写磁盘操作引起的进程切换，指针继续向前走，算法继续对下一个页面进行操作。毕竟，有可能存在一个老的，没有被修改过的页面可以立即使用。

原则上来说，所有的页面都有可能因为磁盘I/O 在某个时钟周期内被调度。为了降低磁盘阻塞，需要设置一个限制，即最大只允许写回 n 个页面。一旦达到该限制，就不允许调度新的写操作。

那么就有个问题，指针会绕一圈回到原点的，如果回到原点，它的起始点会发生什么？这里有两种情况：

- 至少调度了一次写操作
- 没有调度过写操作

在第一种情况中，指针仅仅是不停的移动，寻找一个未被修改过的页面。由于已经调度了一个或者多个写操作，最终会有某个写操作完成，它的页面会被标记为未修改。置换遇到的第一个未被修改过的页面，这个页面不一定是第一个被调度写操作的页面，因为硬盘驱动程序为了优化性能可能会把写操作重排序。

对于第二种情况，所有的页面都在工作集中，否则将至少调度了一个写操作。由于缺乏额外的信息，最简单的方法就是置换一个未被修改的页面来使用，扫描中需要记录未被修改的页面的位置，如果不存在未被修改的页面，就选定当前页面并把它写回磁盘。

### 页面置换算法小结
算法	                             注释
最优算法	                         不可实现，但可以用作基准
NRU(最近未使用) 算法	              和 LRU 算法很相似
FIFO(先进先出) 算法	               有可能会抛弃重要的页面
第二次机会算法	                     比 FIFO 有较大的改善
时钟算法	                         实际使用
LRU(最近最少)算法	                比较优秀，但是很难实现
NFU(最不经常使用)算法	            和 LRU 很类似
老化算法	                        近似 LRU 的高效算法
工作集算法	                       实施起来开销很大
工作集时钟算法	                    比较有效的算法

- 最优算法在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，因此实际上该算法不能使用。然而，它可以作为衡量其他算法的标准。

- NRU 算法根据 R 位和 M 位的状态将页面氛围四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。

- FIFO 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。

- 第二次机会算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。

- 时钟 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。

- LRU 算法是一个非常优秀的算法，但是没有特殊的硬件(TLB)很难实现。如果没有硬件，就不能使用 LRU 算法。

- NFU 算法是一种近似于 LRU 的算法，它的性能不是非常好。

- 老化 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择

最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。WSClock 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。

总之，最好的算法是老化算法和WSClock算法。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。

## 文件
### 文件命名
文件是一种抽象机制，它提供了一种方式用来存储信息以及在后面进行读取。可能任何一种机制最重要的特性就是管理对象的命名方式。在创建一个文件后，它会给文件一个命名。当进程终止时，文件会继续存在，并且其他进程可以使用名称访问该文件。

文件命名规则对于不同的操作系统来说是不一样的，但是所有现代操作系统都允许使用 1 - 8 个字母的字符串作为合法文件名。

某些文件区分大小写字母，而大多数则不区分。UNIX 属于第一类；历史悠久的 MS-DOS 属于第二类（顺便说一句，尽管 MS-DOS 历史悠久，但 MS-DOS 仍在嵌入式系统中非常广泛地使用，因此它绝不是过时的）；因此，UNIX 系统会有三种不同的命名文件：maria、Maria、MARIA 。在 MS-DOS ，所有这些命名都属于相同的文件。

许多操作系统支持两部分的文件名，它们之间用 . 分隔开，比如文件名 prog.c。原点后面的文件称为 文件扩展名(file extension) ，文件扩展名通常表示文件的一些信息。

### 文件结构
三种不同的文件。 a) 字节序列 。b) 记录序列。c) 树

上图中的 a 是一种无结构的字节序列，操作系统不关心序列的内容是什么，操作系统能看到的就是字节(bytes)。其文件内容的任何含义只在用户程序中进行解释。UNIX 和 Windows 都采用这种办法。

图 b 表示在文件结构上的第一部改进。在这个模型中，文件是具有固定长度记录的序列，每个记录都有其内部结构。 把文件作为记录序列的核心思想是：读操作返回一个记录，而写操作重写或者追加一个记录。第三种文件结构如上图 c 所示。在这种组织结构中，文件由一颗记录树构成，记录树的长度不一定相同，每个记录树都在记录中的固定位置包含一个key 字段。这棵树按 key 进行排序，从而可以对特定的 key 进行快速查找。

### 文件类型
很多操作系统支持多种文件类型。例如，UNIX（同样包括 OS X）和 Windows 都具有常规的文件和目录。除此之外，UNIX 还具有字符特殊文件(character special file) 和 块特殊文件(block special file)。常规文件(Regular files) 是包含有用户信息的文件。用户一般使用的文件大都是常规文件，常规文件一般包括 可执行文件、文本文件、图像文件，从常规文件读取数据或将数据写入时，内核会根据文件系统的规则执行操作，是写入可能被延迟，记录日志或者接受其他操作。

### 文件访问
早期的操作系统只有一种访问方式：序列访问(sequential access)。在这些系统中，进程可以按照顺序读取所有的字节或文件中的记录，但是不能跳过并乱序执行它们。顺序访问文件是可以返回到起点的，需要时可以多次读取该文件。当存储介质是磁带而不是磁盘时，顺序访问文件很方便。

在使用磁盘来存储文件时，可以不按照顺序读取文件中的字节或者记录，或者按照关键字而不是位置来访问记录。这种能够以任意次序进行读取的称为随机访问文件(random access file)。许多应用程序都需要这种方式。

随机访问文件对许多应用程序来说都必不可少，例如，数据库系统。如果乘客打电话预定某航班机票，订票程序必须能够直接访问航班记录，而不必先读取其他航班的成千上万条记录。

有两种方法可以指示从何处开始读取文件。第一种方法是直接使用 read 从头开始读取。另一种是用一个特殊的 seek 操作设置当前位置，在 seek 操作后，从这个当前位置顺序地开始读文件。UNIX 和 Windows 使用的是后面一种方式。

### 文件属性
文件包括文件名和数据。除此之外，所有的操作系统还会保存其他与文件相关的信息，如文件创建的日期和时间、文件大小。我们可以称这些为文件的属性(attributes)。有些人也喜欢把它们称作 元数据(metadata)。文件的属性在不同的系统中差别很大。文件的属性只有两种状态：设置(set) 和 清除(clear)。

### 文件操作
使用文件的目的是用来存储信息并方便以后的检索。对于存储和检索，不同的系统提供了不同的操作。以下是与文件有关的最常用的一些系统调用：

- Create，创建不包含任何数据的文件。调用的目的是表示文件即将建立，并对文件设置一些属性。
- Delete，当文件不再需要，必须删除它以释放内存空间。为此总会有一个系统调用来删除文件。
- Open，在使用文件之前，必须先打开文件。这个调用的目的是允许系统将属性和磁盘地址列表保存到主存中，用来以后的快速访问。
- Close，当所有进程完成时，属性和磁盘地址不再需要，因此应关闭文件以释放表空间。很多系统限制进程打开文件的个数，以此达到鼓励用户关闭不再使用的文件。磁盘以块为单位写入，关闭文件时会强制写入最后一块，即使这个块空间内部还不满。
- Read，数据从文件中读取。通常情况下，读取的数据来自文件的当前位置。调用者必须指定需要读取多少数据，并且提供存放这些数据的缓冲区。
- Write，向文件写数据，写操作一般也是从文件的当前位置开始进行。如果当前位置是文件的末尾，则会直接追加进行写入。如果当前位置在文件中，则现有数据被覆盖，并且永远消失。
- append，使用 append 只能向文件末尾添加数据。
- seek，对于随机访问的文件，要指定从何处开始获取数据。通常的方法是用 seek 系统调用把当前位置指针指向文件中的特定位置。seek 调用结束后，就可以从指定位置开始读写数据了。
- get attributes，进程运行时通常需要读取文件属性。
- set attributes，用户可以自己设置一些文件属性，甚至是在文件创建之后，实现该功能的是 set attributes 系统调用。
- rename，用户可以自己更改已有文件的名字，rename 系统调用用于这一目的。

## 目录
文件系统通常提供目录(directories) 或者 文件夹(folders) 用于记录文件的位置，在很多系统中目录本身也是文件。

### 一级目录系统
目录系统最简单的形式是有一个能够包含所有文件的目录。这种目录被称为根目录(root directory)，由于根目录的唯一性，所以其名称并不重要。在最早期的个人计算机中，这种系统很常见，部分原因是因为只有一个用户。下面是一个单层目录系统的例子
![image](https://user-images.githubusercontent.com/81898811/113544249-80412080-961a-11eb-841e-1f4c0a8cf39e.png)
含有四个文件的单层目录系统

该目录中有四个文件。这种设计的优点在于简单，并且能够快速定位文件，毕竟只有一个地方可以检索。这种目录组织形式现在一般用于简单的嵌入式设备（如数码相机和某些便携式音乐播放器）上使用。

### 层次目录系统
对于简单的应用而言，一般都用单层目录方式，但是这种组织形式并不适合于现代计算机，因为现代计算机含有成千上万个文件和文件夹。如果都放在根目录下，查找起来会非常困难。为了解决这一问题，出现了层次目录系统(Hierarchical Directory Systems)，也称为目录树。通过这种方式，可以用很多目录把文件进行分组。进而，如果多个用户共享同一个文件服务器，比如公司的网络系统，每个用户可以为自己的目录树拥有自己的私人根目录。这种方式的组织结构如下
![image](https://user-images.githubusercontent.com/81898811/113544372-b67ea000-961a-11eb-9063-93c624fe3675.png)
根目录含有目录 A、B 和 C ，分别属于不同的用户，其中两个用户个字创建了子目录。用户可以创建任意数量的子目录，现代文件系统都是按照这种方式组织的。

### 路径名
当目录树组织文件系统时，需要有某种方法指明文件名。常用的方法有两种，第一种方式是每个文件都会用一个绝对路径名(absolute path name)，它由根目录到文件的路径组成。

另外一种指定文件名的方法是 相对路径名(relative path name)。它常常和 工作目录(working directory) （也称作 当前目录(current directory)）一起使用。用户可以指定一个目录作为当前工作目录。例如，如果当前目录是 /usr/ast，那么绝对路径 /usr/ast/mailbox可以直接使用 mailbox 来引用。

### 目录操作
不同文件中管理目录的系统调用的差别比管理文件的系统调用差别大。为了了解这些系统调用有哪些以及它们怎样工作，下面给出一个例子（取自 UNIX）。

- Create，创建目录，除了目录项 . 和 .. 外，目录内容为空。
- Delete，删除目录，只有空目录可以删除。只包含 . 和 .. 的目录被认为是空目录，这两个目录项通常不能删除
- opendir，目录内容可被读取。例如，未列出目录中的全部文件，程序必须先打开该目录，然后读其中全部文件的文件名。与打开和读文件相同，在读目录前，必须先打开文件。
- closedir，读目录结束后，应该关闭目录用于释放内部表空间。
- readdir，系统调用 readdir 返回打开目录的下一个目录项。以前也采用 read 系统调用来读取目录，但是这种方法有一个缺点：程序员必须了解和处理目录的内部结构。相反，不论采用哪一种目录结构，readdir 总是以标准格式返回一个目录项。
- rename，在很多方面目录和文件都相似。文件可以更换名称，目录也可以。
-link，链接技术允许在多个目录中出现同一个文件。这个系统调用指定一个存在的文件和一个路径名，并建立从该文件到路径所指名字的链接。这样，可以在多个目录中出现同一个文件。有时也被称为硬链接(hard link)。
- unlink，删除目录项。如果被解除链接的文件只出现在一个目录中，则将它从文件中删除。如果它出现在多个目录中，则只删除指定路径名的链接，依然保留其他路径名的链接。在 UNIX 中，用于删除文件的系统调用就是 unlink。

## 文件系统的实现
### 文件系统布局
文件系统存储在磁盘中。大部分的磁盘能够划分出一到多个分区，叫做磁盘分区(disk partitioning) 或者是磁盘分片(disk slicing)。每个分区都有独立的文件系统，每块分区的文件系统可以不同。磁盘的 0 号分区称为 主引导记录(Master Boot Record, MBR)，用来引导(boot) 计算机。在 MBR 的结尾是分区表(partition table)。每个分区表给出每个分区由开始到结束的地址。

当计算机开始引 boot 时，BIOS 读入并执行 MBR。

### 引导块



----------------------------------------------------------------------
# 操作系统面试集锦
## 虚机和容器的区别
虚机拥有自己独立的基础架构和系统，拥有自己的内核，虚机可以减少在服务器设备上的支出，可以利用一个物理服务器资源切分成多个独立的虚拟机来完成很多工作。虚机的系统完全相互独立，可以在不同的虚机里安装不同的系统环境。并且虚机和主机操作系统隔离，是进行实验和开发应用程序的安全场所。劣势：虚机可能占用主机的大量系统资源，在虚拟服务器上运行单个应用程序可能会增加很多的RAM和CPU的资源消耗。并且迁移虚机上的应用程序也可能很复杂，必须同时迁移应用程序和操作系统。同时在创建虚机是，系统管理程序需要分配专用于VM的硬件资源。

容器不依赖操作系统以及应用程序的环境，是通过linux的namespaces和cgroups技术对应用程序进程进行隔离和限制。但是多个容器共用同一个宿主的内核，只是运行在宿主机上的一种特殊的进程。

## 容器如何工作 cgroup namespace chroot（change root)
namespace的作用是隔离，让应用进程只能看到该namespace内的世界，而cgroups的作用是限制，给这个container的世界围上了一圈看不见的墙。在容器进程启动之前会通过pivot——root或者chroot系统调用改变进程的文件系统从而重新挂载他的整个根目录，这里还有一个rootfs根文件系统，这个的存在就能够使之前的挂在对宿主机不可见。这个挂载在容器的根目录上，用来为容器进程提供隔离后执行环境的文件系统，也就是所谓的容器镜像。但是这个根文件系统只是一个操作系统所包含的文件、配置和目录，并不包括操作系统的内核。所以，同一机器上所有容器都共享宿主机操作系统的内核。-->缺陷：如果容器里的应用程序需要配置内核参数或者跟内核进行直接的交互，这些都是操作了宿主机操作系统的内核，对于该机器的所有容器来说是一个全局变量，牵一发而动全身。  优点：由于根文件系统里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着应用以及运行所需要的所有依赖，都封装在一起了，这就赋予了容器的一致性：无论在本地、云端或者任何地方的机器上，用户只要解压打包好的容器镜像，这个应用程序运行所需要的完整的执行环境就可以被重现出来。

## 容器的优势
容器占用的大小比虚机小很多，可以轻松限制容器的内存和CPU使用率。与部署应用需要部署整个操作系统的虚机相比，容器非常轻巧并且启动迅速，可以快速扩展容器并添加相同的容易。 并且容器对于持续集成和持续部署（ci/cd）的实施也是很好的选择。可以通过在开发人员之间分发和合并镜像来促进协作开发。

## 容器的劣势
容器无法提供与虚机相同的安全性和稳定性，由于共享主机的内核，因此不能像虚机一样完全隔离。 容器是进程级别的隔离，一个容器可以通过影响主机内核的稳定性；来影响其他容器。

## cicd 持续集成 持续发布 jenkins git pipeline
cicd其实就是一个流程，一个管道，用于实现应用开发中的高度持续自动化和持续监控。

持续集成注重将各个开发者的工作集成到一个代码仓库中，目的是尽早发现集成错误，使团队更加紧密结合，更好的协作。持续交付的目的是最小化部署或发布过程中团队固有的摩擦，能够将构建部署的每个步骤自动化，以便任何时刻都能安全的完成代码发布。持续部署是一种更高程度的自动化，无论何时代码有较大改动，都会自动进行构建或者部署。 这三个阶段都是交付流水线的一部分。

### jenkins多环境CI/CD架构设计
- 支持多分支、多环境、多项目、多套配置文件、多编程语言
- 支持一键构建、集群发布
- 支持一键回滚历史版本
- 快捷配置添加新的部署项目
- 支持多个项目使用同一个job发布或回滚
- 另外：也可以根据需要加入gitlab自动触发构建、自动化测试、钉钉通知、邮箱通知等需求

架构设计
CICD架构图
CICD过程主要在两个局域网中执行：构建服务器(开发内网)和部署服务器(生产内网)

自动触发CICD还是手动触发CICD？我认为：

开发环境采用手动触发：因为对于开发环境，提交代码比较频繁，而且有时候提交到git也并不想触发CICD。可以采取每晚定时自动触发CICD，便于异常代码及时抛出。
测试环境采用自动触发：因为测试代码的 git 分支合并是有条件限制的，合并频率比较少。
生产环境采用手动触发：因为生产环境的发布，有严控发布时间的，手动触发控制力强。

## 进程和线程以及协程的区别
Cpu读取硬盘中的程序到内存中，这个在内存中的可执行程序就叫做进程，如果一个程序多次读取到内存中，就变成了多个独立的进程。内存中任何一个地方都有相应的地址方便访问，而在内存中的每个进程自己内部都有一个虚拟独立的地址空间，在进程内就可以根据虚拟地址进行访问。而进程间是如何访问的呢？ 首先进程是程序执行的完整单位，所以大部分时间都是在进程内，那进程间就需要通信，ipc，这可能就需要进行系统调用。每个进程都以为自己独占着整个内存，不需要关心其他的进程的实际位置，这样就把进程很好的分割开了

每个进程首先 有加载的程序，通常只有一个程序计数器记录当前程序执行的位置，会按照程序顺序计算，这里的一个执行流就是一个线程，如果有多个线程的话，就会有多个程序计数器，每个线程独自运行，除此以外，每个线程还会有寄存器、堆栈等程序运行时的状态信息。同时，线程间会共享地址空间、全局变量、打开的文件等等信息。

那为什么在进程中还需要有更小的“进程”--线程呢？ 
我们假设有一个文档编辑器，也就是一个进程，存放着相应的程序和文档，现在用户在第一行末打了一个回车，那我们就需要交互的程序来接受键盘的按下事件，然后布局的程序需要将文字重新计算位置再把它们渲染出来，另外每隔一段时间需要写入的程序来保存文档到硬盘中，这个时候这三个程序最好是能够并行执行，但他们又需要访问修改同一个文档，所以肯定是在同一个进程中，所以这个时候需要更轻量级的线程：交互线程、渲染线程和保存线程。

线程是并行的最小单位，假如只有单核CPU的话，那么一次只能执行一个线程，所以就需要对每个线程轮流执行，每次单个计算的时间就成为了一个CPU时间片，实际只有几十毫秒，用户感觉不到，所以1s内相当于是并行的。存在等待CPU的时候就是就绪状态，一旦CPU过来执行，就会转为运行状态，当CPU转而执行其他线程时，线程就又变成就绪状态，假如线程正在执行中，程序向硬盘发送访问请求，然后等待，这时CPU就变成空转了，所以线程变成阻塞状态，CPU转而执行其他线程，等到硬盘的数据回复，线程从阻塞态转变成就绪状态，等待CPU的再次光临。

进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉。进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。

协程是一种用户态的轻量级线程，协程的调度完全由用户控制，协程是控制了内部的时间片给对应的函数而改变不了CPU给的外部时间片。

1、多进程一般使用multiprocessing库，来利用多核CPU，主要是用在CPU密集型的程序上，当然生产者消费者这种也可以使用。多进程的优势就是一个子进程崩溃并不会影响其他子进程和主进程的运行，但缺点就是不能一次性启动太多进程，会严重影响系统的资源调度，特别是CPU使用率和负载。

2、多线程一般是使用threading库，完成一些IO密集型并发操作。多线程的优势是切换快，资源消耗低，但一个线程挂掉则会影响到所有线程，所以不够稳定。

3、协程一般是使用gevent库

总结一下就是IO密集型一般使用多线程或者多进程，CPU密集型一般使用多进程，强调非阻塞异步并发的一般都是使用协程，当然有时候也是需要多进程线程池结合的，或者是其他组合方式。

## 地址空间管理

## 内存管理

## 系统调用
### 原理
系统有用户态和内存态，当用户需要调用由内核态内提供的程序时，就需要通过系统调用才能实现。一般的，进程是不能访问内核的。它不能访问内核所占内存空间也不能调用内核函数。这个是由CPU硬件决定的，也就是保护模式。系统调用就是一个例外，原理是进程先用适当的值填充寄存器，然后调用一个特殊的指令，这个指令会跳到一个事先定义的内核中的一个位置(当然，这个位置是用户进程可读但是不可写的)。硬件知道一旦你跳到这个位置，你就不是在限制模式下运行的用户，而是作为操作系统的内核--所以你就可以为所欲为。进程可以跳转到的内核位置叫做sysem_call。这个过程检查系统调用号，这个号码告诉内核进程请求哪种服务。然后，它查看系统调用表(sys_call_table)找到所调用的内核函数入口地址。接着，就调用函数，等返回后，做一些系统检查，最后返回到进程(或到其他进程，如果这个进程时间用尽)。

网络相关的都在内核层

### 如何进行系统调用？
Linux系统调用列表
https://www.huaweicloud.com/articles/3aa84d6af3129d6798168a162d5124c8.html
- 进程控制
fork 创建一个新进程
clone 按指定条件创建子进程
execve 运行可执行文件
exit 中止进程
_exit 立即中止当前进程
getdtablesize 进程所能打开的最大文件数
getpid 获取进程标识号
getpriority 获取调度优先级
ptrace 进程跟踪
- 文件系统控制
1. 读写操作
open 打开文件

creat 创建新文件

close 关闭文件描述字

read 读文件

write 写文件
2. 文件系统操作
access 确定文件的可存取性

chdir 改变当前工作目录
chmod 改变文件方式
chown 改变文件的属主或用户组
chroot 改变根目录
stat 取文件状态信息
statfs 取文件系统信息
mkdir 创建目录

mknod 创建索引节点

rmdir 删除目录

rename 文件改名

link 创建链接

- 系统控制
sysinfo 取得系统信息
init_module 初始化模块

- 内存管理

- 网络管理
- 用户管理
- 进程间通信
- 消息
- 管道
- 信号量
- 共享内存

## Nginx
Nginx是一种Web服务器，基于REST架构风格，通过HTTP协议提供各种网络服务。可以支持百万级别的TCP里拦截。是一个跨平台服务器，可以运行在不同操作系统上。

Nginx是高性能的反向代理。

什么是反向代理？
反向代理（Reverse Proxy）方式是指以代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。
反向代理是为服务端服务的，反向代理可以帮助服务器接收来自客户端的请求，帮助服务器做请求转发，负载均衡等。
反向代理对服务端是透明的，对我们是非透明的，即我们并不知道自己访问的是代理服务器，而服务器知道反向代理在为他服务。
如果请求数量比较大，单个服务器解决不了就要增加服务器的数量，然后把请求分到各个服务器上，这个时候就要用到负载均衡。Upstream 指定后端服务器地址列表，在 server 中拦截响应请求，并将请求转发到 Upstream 中配置的服务器列表。但这只是指定了 nginx 需要转发的服务端列表，并没有指定分配策略。默认情况下采用的是轮询策略。

Nginx支持的负载均衡算法有：
- weight轮询(默认，常用)：接收到的请求按照权重分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，Nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。这种方式下，可以给不同的后端服务器设置一个权重值(weight)，用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。ip_hash（常用）：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。
- fair：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是Nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块。url_hash：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在Nginx作为静态服务器的情况下提高缓存效率。同样要注意Nginx默认不支持这种调度算法，要使用的话需要安装Nginx的hash软件包。

动静分离
为了加快服务器的解析速度，可以把动态页面和静态页面交给不同的服务器来解析，加快解析速度，降低原来单个服务器的压力。

### 为什么选择Nginx
- Nginx采用了七层负载均衡 应用层的东西都在用户态
- 采用了IO多路复用epoll
- 轻量级：功能模块少-仅保留了HTTP需要的模块，其他都用插件方式，后天添加； 代码模块化-更适合二次开发
- CPU亲和：把CPU核心和Nginx工作进程绑定，把每个worker进程固定在一个CPU上执行，减少切换CPU的cache miss，从而提高性能


## 负载均衡 七层负载和四层负载
所谓四层就是基于IP+端口的负载均衡；七层就是基于URL等应用层信息的负载均衡；同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。 换句换说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。

所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或七层的信息来决定怎么样转发流量。比如四层的负载均衡，就是通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。

负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息。

### 区别
1. 技术原理上：
所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。
以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。

所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。


2. 应用场景上：
七层应用负载的好处，是使得整个网络更智能化。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。
另外一个常常被提到功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service(DoS)的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转发到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营。另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文，例如SQL Injection等应用层面的特定攻击手段，从应用层面进一步提高系统整体安全。

### 负载均衡软件的优缺点 Nginx和LVS
如果是中小型的Web应用，比如日PV小于1000万，用Nginx就完全可以了；如果机器不少，可以用DNS轮询，LVS所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用LVS。
目前关于网站架构一般比较合理流行的架构方案：Web前端采用Nginx/HAProxy+ Keepalived作负载均衡器；后端采用 MySQL数据库一主多从和读写分离，采用LVS+Keepalived的架构。

- Nginx的优点是：
1.工作在网络的7层之上，可以针对http应用做一些分流的策略
2.Nginx对网络稳定性的依赖非常小，相反LVS对网络稳定性依赖比较大。
3.Nginx安装和配置比较简单，测试起来比较方便，它基本能把错误用日志打印出来。LVS的配置、测试就要花比较长的时间了，LVS对网络依赖比较大。
4.可以承担高负载压力且稳定，在硬件不差的情况下一般能支撑几万次的并发量，负载度比LVS相对小些。
5.Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测。比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障，Nginx会把上传切到另一台服务器重新处理，而LVS就直接断掉了，如果是上传一个很大的文件或者很重要的文件的话，用户可能会因此而不满。

- Nginx的缺点：
1. Nginx仅能支持http、https和Email协议
2. 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测。不支持Session的直接保持，但能通过ip_hash来解决。

- LVS 的优点：
1.抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和cpu资源消耗比较低。
2.配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。
3.工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如LVS+Keepalived。
4.无流量，LVS只分发请求，而流量并不从它本身出去，这点保证了均衡器IO的性能不会受到大流量的影响。
5.应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等。

- LVS的缺点：
1.软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是Nginx/HAProxy+Keepalived的优势所在。
2.如果是网站应用比较庞大的话，LVS/DR+Keepalived实施起来就比较复杂了，特别后面有 Windows Server的机器的话，如果实施及配置还有维护过程就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。


## IO 多路复用 epoll， poll
### 文件描述符
文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。
文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。
### 缓存I/O
缓存I/O又称为标准I/O，大多数文件系统的默认I/O操作都是缓存I/O。在Linux的缓存I/O机制中，操作系统会将I/O的数据缓存在文件系统的页缓存中，即数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。

### 什么是IO多路复用
IO 多路复用是一种同步IO模型，实现一个线程可以监视多个文件句柄；
一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作；
没有文件句柄就绪就会阻塞应用程序，交出CPU。

多路是指网络连接，复用指的是同一个线程

### 为什么又IO多路复用机制？
没有IO多路复用机制时，有BIO、NIO两种实现方式，但它们都有一些问题
- 同步阻塞（BIO）
服务端采用单线程，当 accept 一个请求后，在 recv 或 send 调用阻塞时，将无法 accept 其他请求（必须等上一个请求处理 recv 或 send 完 ）（无法处理并发）

服务端采用多线程，当 accept 一个请求后，开启线程进行 recv，可以完成并发处理，但随着请求数增加需要增加系统线程，大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写实际的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费。


- 同步非阻塞（NIO）
服务器端当 accept 一个请求后，加入 fds 文件描述符集合，每次轮询一遍 fds 集合 recv (非阻塞)数据，没有数据则立即返回错误，每次轮询所有 fd （包括没有发生读写实际的 fd）会很浪费 CPU。

- IO多路复用
多路复用是由进程控制的
服务器端采用单线程通过 select/poll/epoll 等系统调用获取 fd 列表，遍历有事件的 fd 进行 accept/recv/send ，使其能支持更多的并发连接请求。

### IO 多路复用的三种实现
- select
它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以select具有O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

缺点：
1. 单个进程所打开的FD是有限制的，通过 FD_SETSIZE 设置，默认1024 ;
2. 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
3. 对 socket 扫描时是线性扫描，采用轮询的方法，效率较低：当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

- poll
poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。

缺点：
1.每次调用 poll ，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大；
2.对 socket 扫描是线性扫描，采用轮询的方法，效率较低

- epoll event poll
不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。

每一个epoll对象都有一个独立的eventpoll结构体，用于存放通过epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂载在红黑树中，如此，重复添加的事件就可以通过红黑树而高效的识别出来(红黑树的插入时间效率是lgn，其中n为红黑树元素个数)。

而所有添加到epoll中的事件都会与设备(网卡)驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个回调方法。这个回调方法在内核中叫ep_poll_callback,它会将发生的事件添加到rdlist双链表中。

在epoll中，对于每一个事件，都会建立一个epitem结构体，如下所示：
```
struct epitem{
    struct rb_node  rbn;//红黑树节点
    struct list_head    rdllink;//双向链表节点
    struct epoll_filefd  ffd;  //事件句柄信息
    struct eventpoll *ep;    //指向其所属的eventpoll对象
    struct epoll_event event; //期待发生的事件类型
}
```
当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。

通过红黑树和双链表数据结构，并结合回调机制，造就了epoll的高效。 

用法：
1.第一步：epoll_create()系统调用。此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。
2.第二步：epoll_ctl()系统调用。通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。
3.第三部：epoll_wait()系统调用。通过此调用收集收集在epoll监控中已经发生的事件。

优点：
1.没有最大并发连接的限制，能打开的FD的上限远大于1024
2.效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll；
3.内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

缺点：只能工作在 linux 下

epoll 水平触发（LT）与 边缘触发（ET）的区别？
EPOLL事件有两种模型：
- Edge Triggered (ET) 边缘触发只有数据到来,才触发,不管缓存区中是否还有数据。
- Level Triggered (LT) 水平触发只要有数据都会触发。

## Redis IO多路复用技术
redis 是一个单线程却性能非常好的内存数据库， 主要用来作为缓存系统。 redis 采用网络IO多路复用技术来保证在多连接的时候， 系统的高吞吐量。

### 为什么 Redis 中要使用 I/O 多路复用这种技术呢？
首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而  I/O 多路复用 就是为了解决这个问题而出现的。
redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。

## socket 套接字
应用层通过传输层进行数据通信时，TCP和UDP会遇到同时为多个应用程序进程提供并发服务的问题。多个TCP连接或多个应用程序进程可能需要 通过同一个TCP协议端口传输数据。为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了称为套接字 (Socket)的接口，区分不同应用程序进程间的网络通信和连接。

生成套接字，主要有3个参数：通信的目的IP地址、使用的传输层协议(TCP或UDP)和使用的端口号。Socket原意是“插座”。通过将这3个参数结合起来，与一个“插座”Socket绑定，应用层就可以和传输 层通过套接字接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。

Socket可以看成在两个程序进行通讯连接中的一个端点，一个程序将一段信息写入Socket中，该Socket将这段信息发送给另外一个Socket中，使这段信息能传送到其他程序中。

Host A上的程序A将一段信息写入Socket中，Socket的内容被Host A的网络管理软件访问，并将这段信息通过Host A的网络接口卡发送到Host B，Host B的网络接口卡接收到这段信息后，传送给Host B的网络管理软件，网络管理软件将这段信息保存在Host B的Socket中，然后程序B才能在Socket中阅读这段信息。

要通过互联网进行通信，至少需要一对套接字，一个运行于客户机端，称之为ClientSocket，另一个运行于服务器端，称之为serverSocket。     

根据连接启动的方式以及本地套接字要连接的目标，套接字之间的连接过程可以分为三个步骤：服务器监听，客户端请求，连接确认。  

- 服务器监听：是服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态。
- 客户端请求：是指由客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端套接字的地址和端口号，然后就向服务器端套接字提出连接请求。
- 连接确认：是指当服务器端套接字监听到或者说接收到客户端套接字的连接请求，它就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发给客 户端，一旦客户端确认了此描述，连接就建立好了。而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。

## 集群
### 集群和分布式的区别
分布式是指通过网络连接的多个组件，通过交换信息协作而形成的系统。而集群，是指同一种组件的多个实例，形成的逻辑上的整体。可以看出这两个概念并不完全冲突，分布式系统也可以是一个集群，例子就是前面说的zookeeper等，它的特征是服务之间会互相通信协作。是分布式系统不是集群的情况，就是多个不同组件构成的系统；是集群不是分布式系统的情况，比如多个经过负载均衡的HTTP服务器，它们之间不会互相通信，如果不带上负载均衡的部分的话，一般不叫做分布式系统。

通俗地说，前者是多台机器做一个大活的不同分工环节，后者是多台机器共同做一样的活，可以视为一台计算机。

### 云计算平台与之的联系
一个云计算平台，就是通过一套软件系统把分布式部署的资源集中调度使用。要应对大并发，要实现高可用，既需要分布式，也离不开集群。比如负载均衡，如果只是一台服务器，这台宕机了就完蛋了。分布式的难点，就是很多机器做存在依赖关系的不同活儿，这些活儿需要的资源、时间区别可能很大，某些机器还可能罢工，要怎么样才能协调好，做到效率最高，消耗最少，不出错。

### 拜占庭将军
11位拜占庭将军去打仗, 他们各自有权力观测敌情并作出判断, 进攻或撤退, 那么怎么让他们只用传令兵达成一致呢?一种很符合直觉的方法就是投票,每位将军作出决定后都将结果"广播"给其余所有将军, 这样所有将军都能获得同样的11份(包括自己)结果, 取多数, 即可得到全军都同意的行为.但如果这11位将军中有间谍呢? 假设有9位忠诚的将军, 5位判断进攻, 4位判断撤退, 还有2个间谍恶意判断撤退, 虽然结果是错误的撤退, 但这种情况完全是允许的. 因为这11位将军依然保持着状态一致性.暂时从战争故事中抽离出来, 分布式数据库最糟糕的问题绝对不是写入或者读取失败, 而是状态不同步, 还感知不到. 这个的后果就是correctness不能保证, 那程序就没有任何意义了.2个间谍怎么破坏状态一致性呢? 他们跟5位判断进攻的将军说, 我们支持进攻, 那么这5位将军统计发现7位支持进攻, 4位支持撤退, 将发动进攻. 又跟4位撤退的将军说, 我们支持撤退, 一统计, 5票进攻, 6票撤退, 立马撤退. 这场战争必输无疑了.避免这种状态不同步的问题, 我称之为"广义拜占庭将军问题".

Lamport继续将这个问题规约为更小的问题,解决广义拜占庭问题, 必须满足两个条件:对任意忠诚的将军来说, 他们看到的其余将军的决定必须是一样的, 不允许出现前文那种, 5位将军统计结果是7攻4撤, 另外4位将军是5攻6撤. 所有忠诚将军的决定对于其余所有忠诚将军都是一样的. 比如, V(1)表示1号将军的决定. 那么其余所有忠诚将军的统计表上, V(1)一定是一样的. 如果这点不能保证, 说明间谍已经可以直接颠覆指挥系统了, 系统怎样都是无效的, 哪怕达成了一致.上面的条件等价于如何让一个将军(可以是间谍, 论文叫commander)对所有接收者(lieutenant)的指令(order)保持一致? 这个我叫"狭义拜占庭将军问题".

## 进程间通信--互斥 
当两个进程同时访问一个共享变量时，会产生竞争问题。

## 进程间通信--同步 生产者消费者问题    

解决同步时两个进程会一直等待的问题

### 信号量
有一个共享信号量，对其进行down, up 操作。
比如有一个共享变量，进程只能互斥访问，另外有一个信号量，初始时为1，也就是同一时间只允许一个进程进行读写，假如进程1想要访问，就执行一个down操作，此时信号量为0，接着进程2想要访问，也要执行down操作，但此时信号量已经为0，系统就会把该进程睡眠，down操作也一同暂停，然后进程3想要访问，也是一样被睡眠，这时进程1结束操作，把信号量up变为1，共享变量可以访问了，所以由系统随机选择一个睡眠的进程，比如进程3，将其唤醒，进程3的操作继续把信号量减1，变为0，等到进程3结束，up操作变为1，再由系统唤醒进程2，继续down操作，读写变量，结束后up

### 消息队列（MQ）

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

### kafka 实现消息队列的流处理软件
- 可靠性：Kafka是分布式，分区，复制和容错的。
- 可扩展性：Kafka消息传递系统轻松缩放，无需停机。
- 耐用性/持久性：Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。
- 性能：Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。
- 高并发：支持数千个客户端同时读写

## 微服务 zoo keeper
它是一个针对大型应用提供高可用的数据管理、应用程序协调服务的分布式服务框架，基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，提供的功能包括：配置维护、统一命名服务、状态同步服务、集群管理等。

### zoo keeper的特性
1.树状目录结构

每个子目录（如App）被称为znode，我们可以对每个znode进行增删改查。

2. 持久节点

客户端与zookeeper服务端断开连接后，该节点仍然存在。

3.持久有序节点

在持久节点基础上，由zookeeper给该节点名称进行有序编号，如0000001，0000002。

4.临时节点

客户端与zookeeper服务端断开连接后，该节点被删除。临时节点下，不存在子节点。

5.临时有序节点

在临时节点基础上，由zookeeper给该节点名称进行有序编号，如0000001，0000002。

6.节点监听

客户端2注册监听它关心的临时节点SubApp1的变化，当临时节点SubApp1发生变化时（如图中被删除的时候），zookeeper会通知客户端2。

该机制是zookeeper实现分布式协调的重要特性。我们可以通过get，exists，getchildren三种方式对某个节点进行监听。但是该事件只会通知一次。

### 微服务中应用场景
1.分布式锁

分布式锁主要解决不同进程中的资源同步问题。大家可以联想一下单进程中的多线程共享资源的情况，线程需要访问共享资源，首先要获得锁，操作完共享资源后便释放锁。分布式中，上述的锁就变成了分布式锁了。那这个分布式锁又是如何实现呢？

步骤1: 如图，根据zookeeper有序临时节点的特性，每个进程对应连接一个有序临时节点（进程1对应节点/znode/00000001，进程2对应节点/znode/00000002…如此类推）。每个进程监听对应的上一个节点的变化。编号最小的节点对应的进程获得锁，可以操作资源。

![image](https://user-images.githubusercontent.com/81898811/113737141-59750e00-9730-11eb-8ec2-839431017e06.png)

步骤2: 当进程1完成业务后，删除对应的子节点/znode/00000001，释放锁。此时，编号最小的锁便获得锁（即/znode/00000002对应进程）。

重复以上步骤，保证了多个进程获取的是同一个锁，且只有一个进程能获得锁，就是zookeeper分布式锁的实现原理。

2.服务注册与发现
在微服务中，服务提供方把服务注册到zookeeper中心去如图中的Member服务，但是每个应用可能拆分成多个服务对应不同的Ip地址，zookeeper注册中心可以动态感知到服务节点的变化。

服务消费方（Order 服务）需要调用提供方（Member 服务）提供的服务时，从zookeeper中获取提供方的调用地址列表，然后进行调用。这个过程称为服务的订阅。

- 服务注册原理

rpc框架会在zookeeper的注册目录下，为每个应用创建一个持久节点，然后在对应的持久节点下，为每个微服务创建一个临时节点，记录每个服务的URL等信息。

- 服务动态发现原理

由于服务消费方向zookeeper订阅了（监听）服务提供方，一旦服务提供方有变动的时候（增加服务或者减少服务），zookeeper就会把最新的服务提供方列表（member list）推送给服务消费方，这就是服务动态发现的原理。


## Redis缓存
### 定义
Redis是一个 Key-Value 存储系统。为了保证效率，数据都是缓存在内存中。Redis 会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了 master-slave(主从)同步。

### 云存储 key-value store
Key-Value Store 更加注重对海量数据存取的性能、分布式、扩展性支持上，并不需要传统关系数据库的一些特征，因此在分布式环境下的性能相对于传统的关系数据库有较大的提升。

对于云存储来说，也许 key-value 的 store 就是唯一的解决方案了。云存储简单点说就是构建一个大型的存储平台给别人用，这也就意味着在这上面运行的应用其实是不可控的。如果其中某个客户的应用随着用户的增长而不断增长时，云存储供应商是没有办法通过数据库的切割来达到 scale 的，因为这个数据是客户的，供应商不了解这个数据自然就没法作出切割。在这种情况下，key-value 的 store 就是唯一的选择了，因为这种条件下的 scalability 必须是自动完成的，不能有人工干预。这也是为什么几乎所有的现有的云存储都是 key-value 形式的，例如 Amazon的 smipleDB，底层实现就是 key-value，还有 google 的 GoogleAppEngine，采用的是 BigTable的存储形式。

Key-Value Store最大的特点就是它的可扩展性，这也就是它最大的优势。所谓的可扩展性，

在我看来这里包括了两方面内容。一方面，是指 Key-Value Store 可以支持极大的数据的存储，它的分布式的架构决定了只要有更多的机器，就能够保证存储更多的数据。另一方面，是指它可以支持数量很多的并发的查询。

- key- value store的特点

1.Key-value store：一个 key-value 数据存储系统，只支持一些基本操作，如： SET(key, value) 和 GET(key) 等；

2.分布式：多台机器（nodes）同时存储数据和状态，彼此交换消息来保持数据一致，可视为一个完整的存储系统。

3.数据一致：所有机器上的数据都是同步更新的、不用担心得到不一致的结果；

4.冗余：所有机器（nodes）保存相同的数据，整个系统的存储能力取决于单台机器（node）的能力；

5.容错：如果有少数 nodes 出错，比如重启、当机、断网、网络丢包等各种 fault/fail 都不影响整个系统的运行；

6.高可靠性：容错、冗余等保证了数据库系统的可靠性。

### Redis 数据类型
作为 Key-value 型数据库，Redis 也提供了键（Key）和键值（Value）的映射关系。但是，除

了常规的数值或字符串，Redis 的键值还可以是以下形式之一：

- Lists （列表）

- Sets （集合）

- Sorted sets （有序集合）

- Hashes （哈希表）

### Redis持久化

通常，Redis 将数据存储于内存中，或被配置为使用虚拟内存。通过两种方式可以实现数据持久化：使用截图的方式，将内存中的数据不断写入磁盘；或使用类似 MySQL 的日志方式，记录每次更新的日志。前者性能较高，但是可能会引起一定程度的数据丢失；后者相反。

### Redis主从同步

Redis支持将数据同步到多台从库，这种特性对提高读取性能非常有益

### Reidis性能

相比需要依赖磁盘记录每个更新的数据库，基于内存的特性无疑给Redis带来了非常优秀的性能，读写操作之间有显著的性能差异。性能测试结果：

SET操作每秒钟 110000 次，GET操作每秒钟 81000 次，服务器配置如下：

Linux 2.6, Xeon X3320 2.5Ghz.

stackoverflow 网站使用 Redis 做为缓存服务器。

Redis 定位于一个内存数据库，正是由于内存的快速访问特性，才使得 Redis 能够有如此高的性能，才使得 Redis 能够轻松处理大量复杂的数据结构

### 使用redis的好处
1.可以加速读写：Redis是基于内存的数据源，通过缓存加速数据读取速度
2.降低后端负载：后端服务器通过前端缓存降低负载，业务端使用Redis降低后端数据源的负载等

### 使用场景
1.降低后端负载：对高消耗的SQL，例如做排行榜的计算涉及到很多张数据表上数据的很复杂的实时计算，这种计算实际上没有任何意义，
	如果使用Redis缓存，只需要第一次把计算结果写入到Redis缓存中，后续的计算直接在Redis中就可以了，join结果集/分组统计结果进行缓存
2.加速请求响应：由于Redis中的数据是保存在内存中的，利用Redis可以显著的提高IO响应时间
3.大量写请求合并为批量写：如计数器先使用Redis进行累加，最后把结果批量写入到后端数据库中，而不用每次都更新到后端数据库，有效降低后端数据库的负载

### 缓存的更新策略
- LRU/LFU/FIFO算法剔除：Redis使用maxmemory-policy,即Redis中的数据占用的内存超过设定的最大内存时的操作策略
- 超时剔除：对缓存的数据设置过期时间，超过过期时间自动删除缓存数据，然后再次进行缓存，保证与数据库中的数据一致
- 主动更新：开发者控制key的更新周期，当key在后端数据库中发生更新时，向Redis主动发送消息，Redis接收到消息对key进行更新或删除
![image](https://user-images.githubusercontent.com/81898811/113740216-17010080-9733-11eb-951d-99c8269bf922.png)
- 对数据一致性要求不高，即真实数据和缓存数据差别较大对业务影响不大情况下，可以采用最大内存和淘汰策略，内存使用量超过maxmemory-policy时，自动删除数据，而不会影响业务
- 对数据一致性要求较高，即真实数据和缓存数据差别较大会影响业务情况下，可以采用超时剔除和主动更新结合策略，由最大内存和淘汰策略兜底。如果主动更新的功能出现问题失效，没有把一些不必要的数据删除时，Redis占用的内存会越来越多，此时可以给一些有生命周期的key设置比较长的过期时间，然后设置maxmemory和maxmemory-policy，来保证Redis占用的内存超过设置的最大内存时删除一些过期的key，来保证Redis的高可用

### 缓存粒度控制
![image](https://user-images.githubusercontent.com/81898811/113740510-562f5180-9733-11eb-9b90-9d359d4ec0fd.png)

上图中，使用Redis来做缓存，底层使用MySQL来做数据存储源，这种架构下大部分请求由Redis处理，少部分请求到达MySQL。

从MySQL中获取一个用户的所有信息，然后缓存到Redis的数据结构中。

此时需要面对一个问题：缓存这个用户的所有数据信息，还是缓存用户需要的用户信息字段。

可以从三个角度来考虑：

1. 通用性

从通用性角度考虑，缓存全量属性更好。

当用户数据表字段发生改变时，不需要修改程序就可以直接同步修改之后的用户信息到Redis缓存中供用户使用，但是用占用更多的内存空间

2. 占用空间
从占用空间的角度考虑，缓存部分属性更好.

同样当用户数据表字段发生改变时而用户需要这个字段信息时，就需要修改程序源代码来把修改之后的用户信息同步缓存到Redis中，这种情况下占用的内存空间比全量属性占用的内存空间要少

3. 代码维护

从代码维护角度考虑，表面上全量属性更好。

不管数据源中的数据表结构如何改变，都会把所有的数据同步到Redis缓存中，而不需要修改程序源代码，但是在大多数情况下，不会使用到全量数据，只需要缓存需要的数据就可以了，从内存空间消耗及性能方面考虑，使用部分属性更好

### 缓存穿透优化
正常情况下，客户端从缓存中获取数据，如果缓存中没有用户请求需要的数据，就会读取数据源中的数据返回给客户端，同时把数据回写到缓存中。这样当下次客户端再请求这个数据时，就可以直接从缓存中获取数据而不需要经过数据库了。

如果客户端获取一个数据源中没有的key时，先从缓存中获取，获取结果为null，然后到数据源中获取，同样获取结果为null，这样所有的请求都会到达数据源，这就是缓存穿透的基本过程

缓存的存在就是为了保护数据源，缓存穿透之后会对数据源造成巨大的负载和压力，这就失去了缓存的意义。

- 出现穿透的原因

业务程序自身的问题：如无法对缓存进行回写等逻辑bug
恶意攻击，爬虫等

- 解决办法

1. 缓存空对象
缓存空对象是一种简单粗暴的解决方法

当数据源中没有用户请求需要的数据时，会请求数据源，之前的做法是数据源返回一个null，而缓存中并不做回写，缓存空对象的做法就是把null回写到缓存中，暂时解决缓存穿透带来的压力

缺点：

如果是恶意攻击和爬虫等，如果每次请求的数据都不一致，缓存空对象时会在缓存中设置很多的key，即使这些key的值都为空值，也会占用很多的内存空间，此时可以为这个key设置过期时间来降低这样的风险

缓存空对象并设置过期时间，在这个时间内即使数据源恢复正常，请求得到的结果仍然是null，造成缓存层和存储层数据短期不一致。这种情况下，可以通过订阅发布消息来解决，当数据源恢复正常时，会发布消息，然后把正常数据缓存到Redis中

2. 布隆过滤器拦截
使用布隆过滤器可以通过占用很小的内存来对数据进行过滤

布隆过滤器拦截是把所有的key或者离散数据保存到布隆过滤器中，然后使用布隆过滤器在缓存层之前再做一层拦截。

如果请求没有被布隆过滤器拦截，则会到达缓存层获取需要的数据并返回，以达到实际效果

布隆过滤器对于固定的数据可以起到很好的效果，但是对于频繁更新的数据，布隆过滤器的构建会面临很多问题

### 缓存重建
如果重建的是一个热点key，用户访问量非常大。很多用户发送请求获取数据，执行线程从缓存中获取数据，但是此时缓存中并有这些数据，就会从数据源中获取数据，然后重建缓存。

当缓存重建完成，后续的访问才会直接读取缓存数制并返回

在这个过程中，会有很多线程同时查询并重建缓存key，一方面会对数据源造成很大压力，另一方面也会加大响应的时间

### 解决缓存重建
1. 互斥锁

第一个用户从缓存中获取数据，此时缓存中并没有用户需要的数据，会从数据源中重建缓存，

用户在从数据源查询获取数据和重建缓存的过程中加上一把锁，当重建缓存完成以后再把锁解开，并返回

当第二个用户也想从缓存中获取数据时，如果第一个用户重建缓存的过程还没有结束，即锁还没有被解开时，就会等待，同样后续访问的用户也经过这样一个过程

当缓存重建完成，锁被解开，所有的用户请求都从缓存中获取数据并输出

互斥锁解决了缓存大量重建的过程，但是在缓存重建的过程中会有一个等待时间，大量线程被夯住，有可能造成死锁的情况

2. 数据永不过期

在缓存层面，每一个key都不设置过期时间(没有设置expire)
在功能层面中，为每个value添加逻辑过期时间，一旦发现超过逻辑过期时间后，会使用单独的线程去构建缓存
数据永不过期是一个异步的过程，即使缓存重建失败，也不会造成线程夯住的问题
数据永不过期基本杜绝了热点key的重建问题。
数据永不过期好处是：相比于使用互斥锁的方案，不会使用户产生一个等待的时间，而且可以保证只有一个线程来完成数据源的查询和缓存的重建
数据永不过期的缺点：在缓存重建完成之前，用户从缓存中得到的原来的数据有可能与从数据源中的新数据不一致的情况
数据永不过期中设置逻辑过期时间，会为每一个key设置过期时间，会增加维护成本，占用更多的内存空间。

## Kubernetes k8s
k8s是一个docker 容器编排工具, 相当于容器在集群化的调度解决方案

可以将运行 Linux 容器的多组主机聚集在一起，由 Kubernetes 帮助您轻松高效地管理这些集群。而且，这些集群可跨公共云、私有云或混合云部署主机。

真正的生产型应用会涉及多个容器。这些容器必须跨多个服务器主机进行部署。容器安全性需要多层部署，因此可能会比较复杂。但 Kubernetes 有助于解决这一问题。Kubernetes 可以提供所需的编排和管理功能，以便您针对这些工作负载大规模部署容器。借助 Kubernetes 编排功能，您可以构建跨多个容器的应用服务、跨集群调度、扩展这些容器，并长期持续管理这些容器的健康状况。

### k8s有哪些应用
利用 Kubernetes，您能够达成以下目标：

- 跨多台主机进行容器编排。
- 更加充分地利用硬件，最大程度获取运行企业应用所需的资源。
- 有效管控应用部署和更新，并实现自动化操作。
- 挂载和增加存储，用于运行有状态的应用。
- 快速、按需扩展容器化应用及其资源。
- 对服务进行声明式管理，保证所部署的应用始终按照部署的方式运行。
- 利用自动布局、自动重启、自动复制以及自动扩展功能，对应用实施状况检查和自我修复。

但是，Kubernetes 需要依赖其它项目来全面提供这些经过编排的服务。因此，借助其它开源项目可以帮助您将 Kubernetes 的全部功用发挥出来。这些功能包括：

- 注册表，通过 Atomic 注册表或 Docker 注册表等项目实现。
- 联网，通过 OpenvSwitch 和智能边缘路由等项目实现。
- 遥测，通过 heapster、kibana、hawkular 和 elastic 等项目实现。
- 安全性，通过 LDAP、SELinux、RBAC 和 OAUTH 等项目以及多租户层来实现。
- 自动化，参照 Ansible 手册进行安装和集群生命周期管理。
- 服务，可通过自带预建版常用应用模式的丰富内容目录来提供。

### k8s相关术语
- 主机（Master）： 用于控制 Kubernetes 节点的计算机。所有任务分配都来自于此。

- 节点（Node）：负责执行请求和所分配任务的计算机。由 Kubernetes 主机负责对节点进行控制。

- 容器集（Pod）：被部署在单个节点上的，且包含一个或多个容器的容器组。同一容器集中的所有容器共享同一个 IP 地址、IPC、主机名称及其它资源。容器集会将网络和存储从底层容器中抽象出来。这样，您就能更加轻松地在集群中移动容器。

- 复制控制器（Replication controller）：用于控制应在集群某处运行的完全相同的容器集副本数量。

- 服务（Service）：将工作内容与容器集分离。Kubernetes 服务代理会自动将服务请求分发到正确的容器集——无论这个容器集会移到集群中的哪个位置，甚至可以被替换掉。

- Kubelet：运行在节点上的服务，可读取容器清单（container manifest），确保指定的容器启动并运行。

- kubectl： Kubernetes 的命令行配置工具。

### 如何在基础架构中使用k8s
![image](https://user-images.githubusercontent.com/81898811/113821328-8962f680-97ae-11eb-9de3-2050f04e58cf.png)
Kubernetes 基于操作系统运行（例如红帽企业Linux），并与在节点上运行的容器集交互。由 Kubernetes 主机接收管理员（或 DevOps 团队）发出的命令，然后将这些指令转发给从属的节点。这种移交操作与多种服务同时作用，自动确定哪个节点最适合执行该任务。然后，它将在该节点分配资源，并指派容器集来完成任务请求。

因此，就基础架构而言，管理容器的方式基本没变。但您对容器的掌控力得到提升，无需对独立的容器或节点实施微观管理，就能更好地管理容器。当然，某些工作是必须的，但大部分都是关于分配 Kubernetes 主机、定义节点以及定义容器集。

这里面，Docker（点击查看Docker原理） 技术仍然执行它原本的工作。当 kubernetes 将容器集调度到一个节点上时，该节点上的 kubelet 会发送指令让 docker 启动指定的容器。kubelet 随后会不断从 docker 收集这些容器的状态，并将这些信息汇集至主机。Docker 将容器拉至该节点，并按照常规启动和停止这些容器。不同在于，自动化系统要求 docker 在所有节点上对所有容器执行这些操作，而非要求管理员手动操作。

## Docker
是指容器化技术，用于支持创建和使用 Linux® 容器。
借助 Docker，您可将容器当做轻巧、模块化的虚拟机使用。同时，您还将获得高度的灵活性，从而实现对容器的高效创建、部署及复制，并能将其从一个环境顺利迁移至另一个环境，从而有助于您针对云来优化您的应用。
### 原理
Docker 技术使用 Linux 内核和内核功能（例如 Cgroups 和 namespaces）来分隔进程，以便各进程相互独立运行。这种独立性正是采用容器的目的所在；它可以独立运行多种进程、多个应用，更加充分地发挥基础设施的作用，同时保持各个独立系统的安全性。

容器工具（包括 Docker）可提供基于镜像的部署模式。这使得它能够轻松跨多种环境，与其依赖程序共享应用或服务组。Docker 还可在这一容器环境中自动部署应用（或者合并多种流程，以构建单个应用）。

此外，由于这些工具基于 Linux 容器构建，使得 Docker 既易于使用，又别具一格——它可为用户提供前所未有的高度应用程访问权限、快速部署以及版本控制和分发能力。

### Docker技术是否与传统的 Linux 容器相同？
否。Docker 技术最初是基于 LXC 技术构建（大多数人都会将这一技术与“传统的”Linux 容器联系在一起），但后来它逐渐摆脱了对这种技术的依赖。就轻量级 虚拟化 这一功能来看，LXC 非常有用，但它无法提供出色的开发人员或用户体验。除了运行容器之外，Docker 技术还具备其他多项功能，包括简化用于构建容器、传输镜像以及控制镜像版本的流程。

传统的 Linux 容器使用 init 系统来管理多种进程。这意味着，所有应用都作为一个整体运行。与此相反，Docker 技术力争让应用各自独立运行其进程，并提供相应工具，帮助实现这一功能。这种精细化运作模式自有其优势。

### Docker容器的好处
- 模块化
Docker 容器化方法非常注重在不停止整个应用的情况下，单独截取部分应用进行更新或修复的能力。除了这种基于微服务的方法，您还可以采用与面向服务的架构（SOA）类似的使用方法，在多个应用间共享进程。

- 层和镜像版本控制
每个 Docker 镜像文件都包含多个层。这些层组合在一起，构成单个镜像。每当镜像发生改变时，就会创建一个新的镜像层。用户每次发出命令（例如 run 或 copy）时，都会创建一个新的镜像层。

Docker 重复使用这些层来构建新容器，借此帮助加快流程构建。镜像之间会共享中间变化，从而进一步提升速度、规模以及效率。版本控制是镜像层本身自带的能力。每次发生新的更改时，您大都会获得一个内置的更改日志，实现对容器镜像的全盘管控。

- 回滚
回滚也许是层最值得一提的功能。每个镜像都拥有多个层。举例而言，如果您不喜欢迭代后的镜像版本，完全可以通过回滚，返回之前的版本。这一功能还支持敏捷开发方法，帮助持续实施集成和部署（CI/CD），使其在工具层面成为一种现实。

- 快速部署
启动和运行新硬件、实施部署并投入使用，这在过去一般需要数天时间。投入的心力和成本往往也让人不堪重负。基于 Docker 的容器可将部署时间缩短到几秒。通过为每个进程构建容器，您可以快速将这些类似进程应用到新的应用程序中。而且，由于无需启动操作系统即可添加或移动容器，因此大幅缩短了部署时间。除此之外，得益于这种部署速度，您可以轻松无虞、经济高效地创建和销毁容器创建的数据。

因此，Docker 技术是一种更加精细、可控、基于微服务的技术，可为企业提供更高的效率价值。

### Docker的缺点
Docker 本身非常适合用于管理单个容器。但随着您开始使用越来越多的容器和容器化应用，并把它们划分成数百个部分，很可能会导致管理和编排变得非常困难。最终，您需要后退一步，对容器实施分组，以便跨所有容器提供网络、安全、遥测等服务。于是，Kubernetes 应运而生。

## 监控 普罗米修斯+grafana thanos聚合多个普罗米修斯
### Prometheus的优势
Prometheus是一个开源的完整监控解决方案，其对传统监控系统的测试和告警模型进行了彻底的颠覆，形成了基于中央化的规则计算、统一分析和告警的新模型。 相比于传统监控系统Prometheus具有以下优点：
- 易于管理

Prometheus核心部分只有一个单独的二进制文件，不存在任何的第三方依赖(数据库，缓存等等)。唯一需要的就是本地磁盘，因此不会有潜在级联故障的风险。
Prometheus基于Pull模型的架构方式，可以在任何地方（本地电脑，开发环境，测试环境）搭建我们的监控系统。对于一些复杂的情况，还可以使用Prometheus服务发现(Service Discovery)的能力动态管理监控目标。

- 监控服务的内部运行状态

Pometheus鼓励用户监控服务的内部状态，基于Prometheus丰富的Client库，用户可以轻松的在应用程序中添加对Prometheus的支持，从而让用户可以获取服务和应用内部真正的运行状态。

- 强大的数据模型

所有采集的监控数据均以指标(metric)的形式保存在内置的时间序列数据库当中(TSDB)。所有的样本除了基本的指标名称以外，还包含一组用于描述该样本特征的标签。
```
http_request_status{code='200',content_path='/api/path', environment='produment'} => [value1@timestamp1,value2@timestamp2...]

http_request_status{code='200',content_path='/api/path2', environment='produment'} => [value1@timestamp1,value2@timestamp2...]
```
每一条时间序列由指标名称(Metrics Name)以及一组标签(Labels)唯一标识。每条时间序列按照时间的先后顺序存储一系列的样本值。
表示维度的标签可能来源于你的监控对象的状态，比如code=404或者content_path=/api/path。也可能来源于的你的环境定义，比如environment=produment。基于这些Labels我们可以方便地对监控数据进行聚合，过滤，裁剪。

- 强大的查询语言PromQL

Prometheus内置了一个强大的数据查询语言PromQL。 通过PromQL可以实现对监控数据的查询、聚合。同时PromQL也被应用于数据可视化(如Grafana)以及告警当中。
通过PromQL可以轻松回答类似于以下问题：
在过去一段时间中95%应用延迟时间的分布范围？
预测在4小时后，磁盘空间占用大致会是什么情况？
CPU占用率前5位的服务有哪些？(过滤)

- 高效

对于监控系统而言，大量的监控任务必然导致有大量的数据产生。而Prometheus可以高效地处理这些数据，对于单一Prometheus Server实例而言它可以处理：
数以百万的监控指标
每秒处理数十万的数据点。

- 可扩展

Prometheus是如此简单，因此你可以在每个数据中心、每个团队运行独立的Prometheus Sevrer。Prometheus对于联邦集群的支持，可以让多个Prometheus实例产生一个逻辑集群，当单实例Prometheus Server处理的任务量过大时，通过使用功能分区(sharding)+联邦集群(federation)可以对其进行扩展。

- 易于集成
- 可视化
- 开放性

### 普罗米修斯+grafana组成监控系统
整个系统使用了三个组件：

- node-exporter：运行在主机上收集操作系统上各种数据的 agent，prometheus 中称为 exporter

- prometheus server：开源的时序数据库，作为数据存储和分析的中心

- grafana：数据展示分析界面，提供各种强大的 dashboard，可以从多个数据源读取数据，其中就包括 prometheus

NOTE：所有的服务都是通过 docker 启动，需要安装 docker 和 docker-compose

### 开源的大规模普罗米修斯集群解决方案 -- thanos
Prometheus 是 Kubernetes 中默认的监控方案，它专注于告警和收集存储最近的监控指标。但在一定的集群规模下，Prometheus 也暴露出一些问题。例如：如何以经济可靠的方式存储 PB 级别的历史数据，并且不牺牲查询时间？如何通过单一的查询接口访问到不同 Prometheus 服务器上的所有指标数据？能否以某种方式合并采集到的重复数据？针对以上的这些问题， Thanos 提供了高可用的的解决方案，并且它有着不受限制的数据存储能力。

Thanos 使用 Prometheus 存储格式，把历史数据以相对高性价比的方式保存在对象存储里，同时兼有较快的查询速度。此外，它还能对你所有的 Prometheus 提供全局查询视图。

依据 KISS 原则和 Unix 哲学，Thanos 划分如下特定功能的组件。

- 边车组件（Sidecar）：连接Prometheus，并把Prometheus暴露给查询网关（Querier/Query），以供实时查询，并且可以上传Prometheus数据给云存储，以供长期保存；
- 查询网关（Querier/Query）：实现了Prometheus API，与汇集底层组件（如边车组件Sidecar，或是存储网关Store Gateway）的数据；
- 存储网关（Store Gateway）：将云存储中的数据内容暴露出来；
- 压缩器（Compactor）：将云存储中的数据进行压缩和下采样；
- 接收器（Receiver）：从Prometheus’ remote-write WAL（Prometheus远程预写式日志）获取数据，暴露出去或者上传到云存储；
- 规则组件（Ruler）：针对数据进行评估和报警；

## 系统优化

系统优化可以分为两个方面：

- 解决慢设备

I/O慢的话就可以加缓存，使用redis内存型缓存。

为什么要加缓存？--> 因为最快的单元是最靠近CPU的，也就是缓存，缓存的速度快于内存快于磁盘

- 解决资源争抢

可以加队列，防止锁
多分时间片，指定CPU使用这个进程


## 锁


## 日志处理 日志轮询
Linux的系统日志主要保存在/var/log目录中

基本日志格式主要包含四种内容

- 事件发生时间
- 发生事件的主机名
- 发生事件的服务或程序（或内核），包含进程PID
- 事件内容

如果从一开始的所有记录都记录在一个文件中，势必会造成读写变慢、占用增加，甚至增加由于单个文件损坏导致所有日志丢失的风险。为了解决这个问题，Linux系统采用日志轮替方式，将一段时间以前的记录切割打包到另外的存档文件中，而主日志文件从全新重新开始记录。

使用logrotate进行轮询

日志轮替的配置文件为/etc/logrotate.conf，同时具体信息也可以保存在/etc/logrotate.d目录中，在其中可以设置日志轮替信息，参数具体man logrotate查看帮助

参数	说明
daily	按日轮替
weekly	按天轮替
monthly	按月轮替
rotate n	n为数字，为保留的日志文件的个数，0指不备份
compress	对旧的日志进行压缩
create [mode] [owner] [group]	建立新日志的权限模式，所有者和所属组，如create 0640 root adm

### 大规模日志处理 elk
在以前的项目中，如果想要在生产环境需要通过日志定位业务服务的 bug 或者性能问题，则需要运维人员使用命令挨个服务实例去查询日志文件，导致的结果是排查问题的效率非常低。

微服务架构下，服务多实例部署在不同的物理机上，各个微服务的日志被分散储存不同的物理机。集群足够大的话，使用上述传统的方式查阅日志变得非常不合适。因此需要集中化管理分布式系统中的日志，其中有开源的组件如 syslog，用于将所有服务器上的日志收集汇总。

然而集中化日志文件之后，我们面临的是对这些日志文件进行统计和检索，哪些服务有报警和异常，这些需要有详细的统计。所以在之前出现线上故障时，经常会看到开发和运维人员下载了服务的日志，基于 Linux 下的一些命令，如 grep、awk 和 wc 等，进行检索和统计。这样的方式效率低，工作量大，且对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。

ELKB 是一个完整的分布式日志收集系统，很好地解决了上述提到的日志收集难，检索和分析难的问题。


## troubleshooting

1. CPU高

一般先查IO， 步骤就是首先使用top查看最高的进程，然后用ls of查看当前进程的打开状态，接着用strice进入进程，观察系统调用，查看是不是IO调用导致的，查看发生了什么套接字。如果是IO导致的话，可以用io state判断IO状态，看有没有等待。

vm state可以查看机器的状态

2. 如果进程跑着跑着没有连接了，可能是达到了进程设置的最大打开文件数，一般是1024
3. 用户反映 网站访问速度慢，有时无法访问

针对这个问题，第一步要做的是检测网络，可以通过ping命令检查网站的域名解析是否正常，同时，ping服务器地址的延时是否过大等等，通过这种方式，首先排除网络可能出现的问题；如果网络没有问题，接着进入第二步，对linux系统的内存使用状况进行检查，因为网站响应速度慢，一般跟内存关联比较大，通过free、vmstat等命令判断内存资源是否紧缺，如果内存资源不存在问题，进入第三步，检查系统CPU的负载状况，可以通过sar、vmstat、top等命令的输出综合判断CPU是否存在过载问题，如果CPU没有问题，继续进入第四步，检查系统的磁盘I/O是否存在瓶颈，可以通过iostat、vmstat等命令检查磁盘的读写性能，如果磁盘读写也没有问题，linux系统自身的性能问题基本排除，最后要做的是检查程序本身是否存在问题。通过这样的思路，层层检测，步步排查，性能问题就“无处藏身”，查找出现性能问题的环节也就变得非常简单。


## 计算机网络模型
- OSI 七层模型
- TCP/IP 结构
- 五层协议结构
![image](https://user-images.githubusercontent.com/81898811/113845138-c25b9500-97c7-11eb-9d61-719cc1a07118.png)
OSI是Open Systems Interconnect，也就是开放的互联系统，将复杂的互联网系统划分为不同块，方便处理。实际应用中，并没有采用这个理论模型，而是使用TCP/IP协议的四层模型。而5层模型是一个理论上的网络通信模型，方便教学的时候理解，实际上并不存在。

（1）应用层

应用层的任务是通过应用进程间的交互来完成特定网络应用，常见的协议有域名系统DNS，万维网应用的HTTP协议，支持电子邮件的SMTP协议。把应用层交互的数据单元称为报文。

（2）运输层

为两台主机进程之间的通信提供通用的数据传输服务。主要包含两种协议：

传输控制协议 TCP（Transmisson Control Protocol）。提供面向连接的，可靠的数据传输服务。

用户数据报协议 UDP（User Datagram Protocol）。提供无连接的，尽最大努力的数据传输服务（不保证数据传输的可靠性）。

（3）网络层

使用IP协议。网络层有两个任务：

把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。注意：不要把运输层的用户数据报UDP和网络层的IP数据报弄混。
选择合适的路由，找到目的主机
（4）数据链路层

两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装程帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

（5）物理层

物理层的任务就是透明地传输比特流，换句话说实际电路传送后比特流没有发生变化。

## TCP/IP 协议
![image](https://user-images.githubusercontent.com/81898811/113845329-f8991480-97c7-11eb-8cc4-39e5decbd6d2.png)

### TCP和UDP的区别
简单来说：

- TCP：面向连接，面向字节流，可靠，传输慢，有流量控制阻塞控制。
- UDP：广播形式不需要连接，面向报文，不可靠，传输快，无流量控制阻塞控制。

解释一下报文和字节流的区别：

- 字节流：发送次数和接收次数可以不相同，比如向水池倒了20盆水，可以开水龙头一次性全放出。
- 报文：发送次数和接收次数必须相同。

两者的应用场景：

- TCP：邮件，远程登录，文件传输等对准确性要求较高的地方
- UDP：及时通信，比如QQ，网络电话等。

### 三次握手
所谓三次握手是指建立一个TCP连接时，需要客户端和服务器发送3个包。
https://jiangren.work/2019/08/01/Socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8E%9F%E7%90%86/

### 四次挥手
指中断连接时需要发送4个包，此时客户端和服务器均可主动发起挥手操作，只需要调用close()函数即可。
https://jiangren.work/2019/08/01/Socket%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E5%8E%9F%E7%90%86/

https://blog.csdn.net/qzcsu/article/details/72861891

### TCP如何保证可靠
（1）采用三次握手四次挥手保证建立的传输信道是可靠的。

（2）采用了ARQ自动重传请求协议数据传输的可靠性。

（3）采用滑动窗口协议进行流量控制

（4）使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制

### TCP如何进行流量控制
连续ARQ协议通常是结合滑动窗口协议来使用的，发送方需要维持一个发送窗口。
位于发送窗口内的5个分组都可以连续发送出去，而不需要等待对方的确认，这样就提高了信道利用率。发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。

接收方一般都是采用累积确认的方式。收到几个分组后，对按序到达的最后一个分组发送确认。

下载时我们的速度一般都是由慢变快，原因就是拥塞控制。

### TCP如何进行拥塞控制
网络拥塞是指在分组交换网络中传送分组的数目太多时，由于存储转发节点的资源有限而造成网络传输性能下降的情况。

慢开始：不要一开始就发送大量的数据，由小到大逐渐增加拥塞窗口的大小。

拥塞避免：拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1而不是加倍。这样拥塞窗口按线性规律缓慢增长。

快重传：我们可以剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方在收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。快重传规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。

快恢复：主要是配合快重传。当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞），但接下来并不执行慢开始算法，因为如果网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。

## DNS协议和ARP协议
为什么这两个要放在一起说呢？因为这两个协议都是用于地址间的转化，都是起到了翻译官的职责。

### DNS解析过程
DNS (Domain Name System) 是 域名系统 的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于 TCP/IP 网络，它从事将主机名或域名转换为实际 IP 地址的工作，类似于翻译官。

DNS查询时优先考虑本地的Host文件和本地的DNS解析器是否保留有缓存映射，如果没有就向上一级请求。依次按照DNS根服务器，DNS顶层服务器，DNS管理方服务器的顺序请求。

所谓递归查询就是变更查询者，迭代查询则没有变更：这个例子中查询者由客户端变为了本地DNS服务器，所以是递归查询。

### 什么是MAC地址
MAC地址是数据链路层和物理层使用的地址是硬件地址，IP地址网络层和以上各层使用的地址，是一种逻辑地址。在发送数据时，数据从高层到低层，然后才到通信链路上传输。使用IP地址的IP数据报一旦交给了数据链路层，就被封装成了MAC帧。MAC帧在传送时使用的源地址和目的地址都是硬件地址。

### ARP协议工作机制是什么？
ARP（Address Resolution Protocol）即地址解析协议， 用于实现从 IP 地址到 MAC 地址的映射，即询问目标IP对应的MAC地址。

在每台安装有TCP/IP协议的电脑或路由器里都有一个ARP缓存表，表里的IP地址与MAC地址是一对应的，如下表所示。

解析MAC地址时，主机A首先在其ARP高速缓存中查找有无主机B的IP地址。

如果没有就就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。网络中所有的主机收到这个ARP请求后，会检查数据包中的目的IP是否和自己的IP地址一致。如果相同，该主机首先将发送端的MAC地址和IP地址添加到自己的ARP列表中，如果ARP表中已经存在该IP的信息，则将其覆盖，然后给源主机发送一个ARP响应数据包，告诉对方自己是它需要查找的MAC地址。收到后在其ARP高速缓存中写入主机B的IP地址到硬件地址的映射。并且采用LRU机制，及时淘汰。

## HTTP协议

### 常见状态码
![image](https://user-images.githubusercontent.com/81898811/113847022-a2c56c00-97c9-11eb-97be-13c1a31b8f48.png)
200 OK 请求正常处理


204 请求处理成功 但是没有任何资源返回给客户端(一般用于只需客户端向服务端发送消息)


206 对资源的某一部分请求 响应报文中包含由 Content-Range 指定范围的实体内容


301永久重定向
如果把资源对应的URI保存为书签，则此时书签会根据Localtion首部字段提示的URI重新保存


302 临时重定向 临时地从旧地址A跳转到地址B


303 和301，302类似 当使用post方法访问一个资源时，把客户端以get的方式重定向到对应的URI，返回303状态码


304 资源已经找到，但是不满足条件，所以不把资源返回给客户端。常用于协商缓存。


400 请求报文内有语法错误


401 该状态码表示发送的请求需要通过HTTP认证，初次收到401响应浏览器弹出认证的对话窗口。若收到第二次401状态码，则说明第一次验证失败。


403 请求资源的访问被服务器拒绝，一般是未获得文件系统的访问权限，访问权限出现问题。


404 服务器上找不到请求资源 或路径错误


405 请求方法被服务端识别，但是服务端禁止使用该方法。可以用OPTIONS来查看服务器允许哪些访问方法


500 服务器端在执行请求时出错，一般是因为web应用出现bug


502 代理服务器或网关从上游服务器中收到无效响应


503 服务器暂时处于超负载或停机维护，目前无法处理请求

### 301和302的区别
301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（用户看到的效果就是他输入的地址A瞬间变成了另一个地址B）——这是它们的共同点。
  他们的不同在于。301表示旧地址A的资源已经被永久地移除了(这个资源不可访问了)，搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。 SEO302好于301

### 重定向原因
- 网站调整（如改变网页目录结构）；
- 网页被移到一个新地址；
- 网页扩展名改变(如应用需要把.php改成.Html或.shtml)。
这种情况下，如果不做重定向，则用户收藏夹或搜索引擎数据库中旧地址只能让访问客户得到一个404页面错误信息，访问流量白白丧失；再者某些注册了多个域名的网站，也需要通过重定向让访问这些域名的用户自动跳转到主站点等。

### HTTP协议和其他协议之间的关系
HTTP(超文本传输协议)是利用TCP在两台电脑(通常是Web服务器和客户端)之间传输信息的协议。如果TCP是高速路，HTTP就是卡车。Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们能方便地使用TCP/IP协议。

### HTTP长连接和短连接
短连接：客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

长连接：客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。有一个保持时间。

### HTTP和HTTPS的区别
HTTP：运行在TCP之上，明文传输，客户端与服务器端都无法验证对方的身份

HTTPS：Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP

### GET和POST的区别
- GET用于从服务器获取资源，POST用于更新服务器的资源
- GET不会改变服务器的资源，而POST会
- GET请求的数据会附在URL之后，比如http:localhost:8080/id=101?，而POST的数据则是放在请求体中。因此，GET不安全，GET的长度受限制。

### Cookie，session，token
Cookie和Session都是客户端与服务器之间保持状态的解决方案，具体来说，cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。

Cookie实际上是一小段文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器，服务器检查该Cookie，以此来辨认用户状态。

Session的区别在于，会话状态完全保存在服务器。客户端请求服务器，如果服务器记录该用户状态，就获取Session来保存状态，这时，如果服务器已经为此客户端创建过session就按照sessionid把这个session检索出来使用。服务器Session常常依赖于Cookie机制检索ID，但Cookie被禁用时也有其他方法比如URL重写机制。

session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号sessionId，通常存放于cookie中。服务器收到cookie后解析出sessionId，再去session列表中查找，才能找到相应session。依赖cookie

cookie类似一个令牌，装有sessionId，存储在客户端，浏览器通常会自动添加。

token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户。需要开发者手动添加。

### HTTP请求报文和响应报文的格式
请求报文格式：

- 请求行（请求方法+URI协议+版本）
- 请求头部
- 空行
- 请求主体
```
GET/sample.jspHTTP/1.1 请求行
Accept:image/gif.image/jpeg, 请求头部
Accept-Language:zh-cn
Connection:Keep-Alive
Host:localhost
User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
Accept-Encoding:gzip,deflate

username=jinqiao&password=1234 请求主体
```
响应报文：

- 状态行（版本+状态码+原因短语）
- 响应首部
- 空行
- 响应主体

```
HTTP/1.1 200 OK
Server:Apache Tomcat/5.0.12
Date:Mon,6Oct2003 13:23:42 GMT
Content-Length:112

<html>
    <head>
        <title>HTTP响应示例<title>
    </head>
    <body>
        Hello HTTP!
    </body>
</html>
```

## 打开网站经过的过程 DNS解析
DNS 你知道这个东西是什么就行, 实际上就是把一个域名翻译成IP用的, 俗称解析. 因为这个考点有的时候可能会问你打开会经历什么过程.一般来说简化下来是这几步
1. DNS 解析域名成目标IP
2. 从本机发起到目标IP的TCP请求
3. 建立TCP连接后, 开始HTTP协议通信

## 算法题

